{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836cd974-152b-4b90-8d0d-0ee0974d5670",
   "metadata": {},
   "source": [
    "# Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0057cadb-6342-4589-931b-2b5d1b66a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm \n",
    "from datasets import  load_from_disk\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PatientTrajectoryForecasting.utils.utils import (\n",
    "    load_data,\n",
    "    get_paths,\n",
    ")\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1881181-6e7f-47a4-bdac-14edee408b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, source_vocab_size, embedding_dim = 2000, hidden_dim = 2000, n_layers = 1, dropout_prob = 0.5):\n",
    "        super().__init__()\n",
    " \n",
    "        self.embedding = nn.Embedding(source_vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout_prob, batch_first = True)\n",
    " \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    " \n",
    "    def forward(self, input_batch):\n",
    "        embed = self.dropout(self.embedding(input_batch))\n",
    "        outputs, hidden = self.rnn(embed)\n",
    " \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bff45b-3f2a-4354-a983-edb06b685346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepDecoder(nn.Module):\n",
    "    def __init__(self, target_vocab_size, embedding_dim = 2000, hidden_dim = 2000, n_layers = 1, dropout_prob = 0.5):\n",
    "        super().__init__()\n",
    "        # self.target_vocab_size will be used later\n",
    "        self.target_vocab_size = target_vocab_size\n",
    " \n",
    "        self.embedding = nn.Embedding(target_vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=dropout_prob, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, target_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    " \n",
    "    def forward(self, target_token, hidden):\n",
    "        embedding_layer = self.dropout(self.embedding(target_token))\n",
    "        embedding_layer = embedding_layer.unsqueeze(1) if embedding_layer.ndim == 2 else embedding_layer\n",
    "        output, hidden = self.rnn(embedding_layer, hidden)\n",
    " \n",
    "        linear = self.fc(output.squeeze(0))\n",
    " \n",
    "        return linear, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9e02e1-74c5-48cc-b147-b47ebf3b1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, one_step_decoder, device):\n",
    "        super().__init__()\n",
    "        self.one_step_decoder = one_step_decoder\n",
    "        self.device = device\n",
    " \n",
    "    def forward(self, target, hidden):\n",
    "        batch_size, target_len  = target.shape[0], target.shape[1]\n",
    "        target_vocab_size = self.one_step_decoder.target_vocab_size\n",
    "        # Store the predictions in an array for loss calculations\n",
    "        predictions = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
    "        # Take the very first word token, which will be sos\n",
    "        seq = target[:, 0]\n",
    "        \n",
    "        # Loop through all the time steps\n",
    "        for t in range(target_len):\n",
    "            predict, hidden = self.one_step_decoder(seq, hidden)\n",
    " \n",
    "            predictions[:,t] = predict.squeeze(1)\n",
    "            seq = predict.argmax(-1).squeeze(1)      \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b465ec8b-3675-4aea-a5b0-7ce885ad5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    " \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder        \n",
    " \n",
    "    def forward(self, source, target):\n",
    "        \n",
    "        outputs, hidden = self.encoder(source)\n",
    "        outputs= self.decoder(target, hidden)\n",
    "                    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84b2411-e841-45f7-a273-5174534e7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForcastWithNotes(Dataset):\n",
    "    def __init__(self, source_sequences, target_sequences, hospital_ids, tokenized_notes):\n",
    "        self.source_sequences = source_sequences\n",
    "        self.target_sequences = target_sequences\n",
    "        self.hospital_ids = hospital_ids\n",
    "        self.tokenized_notes = load_from_disk(tokenized_notes)\n",
    "    def __len__(self):\n",
    "        return len(self.source_sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        hospital_ids = self.hospital_ids[idx]\n",
    "        hospital_ids_lens = len(hospital_ids)\n",
    "\n",
    "        return  {'source_sequences':torch.tensor(self.source_sequences[idx]),\n",
    "                 'target_sequences': torch.tensor(self.target_sequences[idx]),\n",
    "                 'tokenized_notes':self.tokenized_notes[hospital_ids],\n",
    "                 'hospital_ids_lens': hospital_ids_lens}\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    source_sequences = [item['source_sequences'] for item in batch]\n",
    "    target_sequences = [item['target_sequences'] for item in batch]\n",
    "    \n",
    "    source_sequences = torch.stack(source_sequences, dim=0)\n",
    "    target_sequences = torch.stack(target_sequences, dim=0)\n",
    "\n",
    "    return {\n",
    "        'source_sequences': source_sequences,\n",
    "        'target_sequences': target_sequences,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71731f74-65d0-4c2c-afe6-1f977ad0b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_to_new_ids_source file not availble, mapping is the same as the old one\n"
     ]
    }
   ],
   "source": [
    "with open('PatientTrajectoryForecasting/paths.yaml', 'r') as file:\n",
    "        path_config = yaml.safe_load(file)\n",
    "\n",
    "train_data_path = get_paths(path_config,\n",
    "                        'SDP',\n",
    "                        False,\n",
    "                        False,\n",
    "                        train = True,\n",
    "                        processed_data = True,\n",
    "                        with_notes = True)\n",
    "\n",
    "\n",
    "source_sequences, target_sequences, source_tokens_to_ids, target_tokens_to_ids, _, __, hospital_ids_source = load_data(train_data_path['processed_data_path'],\n",
    "                                                                                                                   processed_data = True, reindexed = True)\n",
    "# Load the datasets\n",
    "train_dataset = torch.load('final_dataset/train_dataset.pth')\n",
    "val_dataset = torch.load('final_dataset/val_dataset.pth')\n",
    "test_dataset = torch.load('final_dataset/test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e462553a-cc91-4701-8a4e-4ac684dfbe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(source_tokens_to_ids, target_tokens_to_ids):\n",
    "    # Define the required dimensions and hyper parameters\n",
    "    embedding_dim = 2000\n",
    "    hidden_dim = 2000\n",
    "    dropout = 0.5\n",
    " \n",
    "    # Instanciate the models\n",
    "    encoder = Encoder(len(source_tokens_to_ids), embedding_dim, hidden_dim, n_layers=2, dropout_prob=dropout)\n",
    "    one_step_decoder = OneStepDecoder(len(target_tokens_to_ids), embedding_dim, hidden_dim, n_layers=2, dropout_prob=dropout)\n",
    "    decoder = Decoder(one_step_decoder, DEVICE)\n",
    " \n",
    "    model = EncoderDecoder(encoder, decoder)\n",
    " \n",
    "    model = model.to(DEVICE)\n",
    " \n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adadelta(model.parameters())\n",
    " \n",
    "    # Makes sure the CrossEntropyLoss ignores the padding tokens.\n",
    "    TARGET_PAD_IDX = target_tokens_to_ids['PAD'] # target pad token\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=TARGET_PAD_IDX)\n",
    " \n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f95ffb-8efb-4a4e-9cde-342b4a7fe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 384\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                                  shuffle = True,\n",
    "                                  batch_size = batch_size,\n",
    "                                  num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                                  pin_memory = True,\n",
    "                                  collate_fn = custom_collate_fn)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            shuffle = False,\n",
    "                            batch_size = batch_size * 2,\n",
    "                            num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                            pin_memory = True,\n",
    "                            collate_fn = custom_collate_fn)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             shuffle = False,\n",
    "                             batch_size = batch_size * 2,\n",
    "                             num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                             pin_memory = True,\n",
    "                             collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f733a0f-6b02-4c67-8f28-be4c172fc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iterator, valid_iterator, source_tokens_to_ids, target_tokens_to_ids, epochs=20):\n",
    "    model, optimizer, criterion = create_model(source_tokens_to_ids, target_tokens_to_ids)\n",
    " \n",
    " \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        pbar = tqdm(total=len(train_iterator), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}', unit=' batches', ncols=200)\n",
    " \n",
    "        training_loss = []\n",
    "        # set training mode\n",
    "        model.train()\n",
    " \n",
    "        # Loop through the training batch\n",
    "        for i, batch in enumerate(train_iterator):\n",
    "            # Get the source and target tokens\n",
    "            src = batch['source_sequences'].to(DEVICE)\n",
    "            trg = batch['target_sequences'].to(DEVICE)\n",
    " \n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            # Forward pass\n",
    "            output = model(src, trg)\n",
    " \n",
    "            # reshape the output\n",
    "            output_dim = output.shape[-1]\n",
    " \n",
    "            # Discard the first token as this will always be 0\n",
    "            output = output[:,1:].contiguous().view(-1, output.size(-1))\n",
    " \n",
    "            # Discard the bos token from target\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    " \n",
    "            # Calculate the loss\n",
    "            loss = criterion(output, trg)\n",
    " \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    " \n",
    "            optimizer.step()\n",
    " \n",
    "            training_loss.append(loss.item())\n",
    " \n",
    "            pbar.set_postfix(\n",
    "                epoch=f\" {epoch}, train loss= {round(sum(training_loss) / len(training_loss), 4)}\", refresh=True)\n",
    "            pbar.update()\n",
    " \n",
    "        with torch.inference_mode():\n",
    "            # Set the model to eval\n",
    "            model.eval()\n",
    " \n",
    "            validation_loss = []\n",
    " \n",
    "            # Loop through the validation batch\n",
    "            for i, batch in enumerate(valid_iterator):\n",
    "                src = batch['source_sequences'].to(DEVICE)\n",
    "                trg = batch['target_sequences'].to(DEVICE)\n",
    " \n",
    "                # Forward pass\n",
    "                output = model(src, trg)\n",
    " \n",
    "                output = output[:,1:].contiguous().view(-1, output.size(-1))\n",
    "                trg = trg[:,1:].contiguous().view(-1)\n",
    " \n",
    "                # Calculate Loss\n",
    "                loss = criterion(output, trg)\n",
    " \n",
    "                validation_loss.append(loss.item())\n",
    " \n",
    "        pbar.set_postfix(\n",
    "            epoch=f\" {epoch}, train loss= {round(sum(training_loss) / len(training_loss), 4)}, val loss= {round(sum(validation_loss) / len(validation_loss), 4)}\",\n",
    "            refresh=False)\n",
    " \n",
    "        pbar.close()\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2ec373-1578-4d9c-bf0a-dddcebb788fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [02:04<00:00,  1.80s/ batches, epoch=1, train loss= 5.0685, val loss= 5.2653]                                                                                                    \n",
      "100%|██████████| 69/69 [02:02<00:00,  1.77s/ batches, epoch=2, train loss= 4.7469, val loss= 5.1992]                                                                                                    \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=3, train loss= 4.7225, val loss= 5.3681]                                                                                                    \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=4, train loss= 4.718, val loss= 5.1544]                                                                                                     \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=5, train loss= 4.7057, val loss= 5.4226]                                                                                                    \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.75s/ batches, epoch=6, train loss= 4.703, val loss= 5.071]                                                                                                      \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=7, train loss= 4.7059, val loss= 4.989]                                                                                                     \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=8, train loss= 4.684, val loss= 5.0483]                                                                                                     \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=9, train loss= 4.6886, val loss= 5.2055]                                                                                                    \n",
      "100%|██████████| 69/69 [02:00<00:00,  1.75s/ batches, epoch=10, train loss= 4.6905, val loss= 4.913]                                                                                                    \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=11, train loss= 4.6889, val loss= 4.9363]                                                                                                   \n",
      "100%|██████████| 69/69 [02:00<00:00,  1.75s/ batches, epoch=12, train loss= 4.6838, val loss= 4.9006]                                                                                                   \n",
      "100%|██████████| 69/69 [02:00<00:00,  1.75s/ batches, epoch=13, train loss= 4.6764, val loss= 5.0792]                                                                                                   \n",
      "100%|██████████| 69/69 [02:00<00:00,  1.75s/ batches, epoch=14, train loss= 4.6866, val loss= 4.9873]                                                                                                   \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=15, train loss= 4.6857, val loss= 4.8768]                                                                                                   \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=16, train loss= 4.6787, val loss= 4.8644]                                                                                                   \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=17, train loss= 4.6662, val loss= 5.2421]                                                                                                   \n",
      "100%|██████████| 69/69 [02:00<00:00,  1.75s/ batches, epoch=18, train loss= 4.6805, val loss= 4.895]                                                                                                    \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=19, train loss= 4.6701, val loss= 5.1004]                                                                                                   \n",
      "100%|██████████| 69/69 [02:01<00:00,  1.76s/ batches, epoch=20, train loss= 4.6759, val loss= 4.9008]                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = train(train_dataloader, test_dataloader, source_tokens_to_ids, target_tokens_to_ids, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f95ef8f8-c9d6-405a-be66-ff038a4922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e12187a-c996-4d28-98f1-ad6e4ddc0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences_doctor_ai(model, dataloader : torch.utils.data.dataloader.DataLoader,\n",
    "                            target_tokens_to_ids : Dict[str, int] =  None, max_len : int = 150,\n",
    "                            DEVICE : str ='cuda:0'):\n",
    "    model.eval()\n",
    "    pred_trgs = []\n",
    "    targets = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader, desc='scoring'):\n",
    "            batch_pred_trgs = []\n",
    "            batch_targets = []\n",
    "            source_input_ids, target_input_ids = batch['source_sequences'].to(DEVICE),batch['target_sequences'].to(DEVICE)\n",
    "            outputsDecoder, hidden = model.encoder(source_input_ids)\n",
    "            next_token = torch.tensor(target_tokens_to_ids['BOS'], device= DEVICE).repeat(source_input_ids.size(0)).unsqueeze(1)\n",
    "            pred_trg = torch.tensor(target_tokens_to_ids['BOS'], device= DEVICE).repeat(source_input_ids.size(0)).unsqueeze(1)\n",
    "            for i in range(max_len):\n",
    "                embedding_layer = model.decoder.one_step_decoder.dropout(model.decoder.one_step_decoder.embedding(next_token))\n",
    "                outputs, hidden = model.decoder.one_step_decoder.rnn(embedding_layer, hidden)\n",
    "        \n",
    "                linear = model.decoder.one_step_decoder.fc(outputs.squeeze(0))\n",
    "                next_token = torch.argmax(linear, dim=-1)\n",
    "                pred_trg = torch.cat((pred_trg, next_token), dim=1)\n",
    "                eov_mask = next_token == target_tokens_to_ids['EOV']\n",
    "                if eov_mask.any():\n",
    "                    # extend with sequences that have reached EOV\n",
    "                    batch_pred_trgs.extend(pred_trg[eov_mask.squeeze(-1)].tolist())\n",
    "                    batch_targets.extend(target_input_ids[eov_mask.squeeze(-1)].tolist())\n",
    "                    # break if all have reached EOV\n",
    "                    if eov_mask.all():\n",
    "                        break  \n",
    "                    # edit corresponding target sequences\n",
    "                    target_input_ids = target_input_ids[~eov_mask.squeeze(-1)]\n",
    "                    pred_trg = pred_trg[~eov_mask.squeeze(-1)]\n",
    "                    hidden = hidden[:,~eov_mask.squeeze(-1),:]\n",
    "                    next_token = [~eov_mask.squeeze(-1)]\n",
    "            if source_input_ids.size(0) != len(batch_pred_trgs):\n",
    "                    batch_pred_trgs.extend(pred_trg.tolist())\n",
    "                    batch_targets.extend(target_input_ids.tolist())\n",
    "            pred_trgs.extend(batch_pred_trgs)\n",
    "            targets.extend(batch_targets)\n",
    "    return pred_trgs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac64aeb3-818f-450b-84f5-ca3d1e6a8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scoring: 100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_trgs, targets = get_sequences_doctor_ai(model, test_dataloader, target_tokens_to_ids, max_len=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b44245b-624b-4724-8f2f-91b012383150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sifal.klioui/PatientTrajectoryForecasting\n"
     ]
    }
   ],
   "source": [
    "cd PatientTrajectoryForecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77999498-88bc-48e4-8588-d61603cf371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_map@20': 0.15164410490104094, 'test_map@40': 0.15204619577357814, 'test_map@60': 0.15204619577357814} {'test_recall@20': 0.21991012781971214, 'test_recall@40': 0.21991012781971214, 'test_recall@60': 0.21991012781971214}\n"
     ]
    }
   ],
   "source": [
    "from utils.eval import mapk, recallTop\n",
    "\n",
    "\n",
    "ks = [20, 40, 60]\n",
    "\n",
    "test_mapk = {f\"test_map@{k}\": mapk(targets, pred_trgs, k) for k in ks}\n",
    "test_recallk = {f\"test_recall@{k}\": recallTop(targets, pred_trgs, rank = [k])[0] for k in ks}\n",
    "print(test_mapk, test_recallk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dude",
   "language": "python",
   "name": "mimibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
