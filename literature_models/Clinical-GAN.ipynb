{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836cd974-152b-4b90-8d0d-0ee0974d5670",
   "metadata": {},
   "source": [
    "# Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b12945f-ce1c-4f73-89a2-5bcf789f06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from tqdm import tqdm \n",
    "from datasets import  load_from_disk\n",
    "from typing import Tuple, List\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PatientTrajectoryForecasting.utils.utils import (\n",
    "    load_data,\n",
    "    get_paths,\n",
    ")\n",
    "\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f374d46-cb9d-47ec-9249-a475b98a45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clinical_GAN.models import Encoder, Decoder, Generator, Discriminator\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import itertools\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b133c779-95fd-446e-b69d-d1e27bbd9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForcastWithNotes(Dataset):\n",
    "    def __init__(self, source_sequences, target_sequences, hospital_ids, tokenized_notes):\n",
    "        self.source_sequences = source_sequences\n",
    "        self.target_sequences = target_sequences\n",
    "        self.hospital_ids = hospital_ids\n",
    "        self.tokenized_notes = load_from_disk(tokenized_notes)\n",
    "    def __len__(self):\n",
    "        return len(self.source_sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        hospital_ids = self.hospital_ids[idx]\n",
    "        hospital_ids_lens = len(hospital_ids)\n",
    "\n",
    "        return  {'source_sequences':torch.tensor(self.source_sequences[idx]),\n",
    "                 'target_sequences': torch.tensor(self.target_sequences[idx]),\n",
    "                 'tokenized_notes':self.tokenized_notes[hospital_ids],\n",
    "                 'hospital_ids_lens': hospital_ids_lens}\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    source_sequences = [item['source_sequences'] for item in batch]\n",
    "    target_sequences = [item['target_sequences'] for item in batch]\n",
    "    \n",
    "    source_sequences = torch.stack(source_sequences, dim=0)\n",
    "    target_sequences = torch.stack(target_sequences, dim=0)\n",
    "\n",
    "    return {\n",
    "        'source_sequences': source_sequences,\n",
    "        'target_sequences': target_sequences,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4d6553-c07d-4322-a59f-f3e70ae29db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_to_new_ids_source file not availble, mapping is the same as the old one\n"
     ]
    }
   ],
   "source": [
    "with open('PatientTrajectoryForecasting/paths.yaml', 'r') as file:\n",
    "        path_config = yaml.safe_load(file)\n",
    "\n",
    "train_data_path = get_paths(path_config,\n",
    "                        'SDP',\n",
    "                        False,\n",
    "                        False,\n",
    "                        train = True,\n",
    "                        processed_data = True,\n",
    "                        with_notes = True)\n",
    "\n",
    "\n",
    "source_sequences, target_sequences, source_tokens_to_ids, target_tokens_to_ids, _, __, hospital_ids_source = load_data(train_data_path['processed_data_path'],\n",
    "                                                                                                                   processed_data = True, reindexed = True)\n",
    "reverseOutTypes = {v:source_tokens_to_ids[k] for k,v in target_tokens_to_ids.items()}\n",
    "# Load the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353e3cc3-1ee0-40b5-958d-1ab8aa8e02a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af6f510-42e2-45f0-8272-5bc751cf5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load('final_dataset/train_dataset.pth')\n",
    "val_dataset = torch.load('final_dataset/val_dataset.pth')\n",
    "test_dataset = torch.load('final_dataset/test_dataset.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bdc3f1d-f582-416f-9299-6f2221e11515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindLR(_LRScheduler):\n",
    " \n",
    "    def __init__(self, optimizer, max_steps, max_lr=10):\n",
    "        self.max_steps = max_steps\n",
    "        self.max_lr = max_lr\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [base_lr * ((self.max_lr / base_lr) ** (self.last_epoch / (self.max_steps - 1)))\n",
    "                for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class NoamLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, warmup_steps,factor =1,model_size=256):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.model_size = model_size\n",
    "        self.factor = factor\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = max(1, self.last_epoch)\n",
    "        #scale = self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5))\n",
    "        scale = self.factor * (self.warmup_steps ** 0.5 * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5)))\n",
    "        #scale = self.factor * (self.model_size ** (-0.5) * min(last_epoch ** (-0.5), last_epoch * self.warmup_steps ** (-1.5)))\n",
    "        return [base_lr * scale for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "def linear_combination(x, y, epsilon): \n",
    "    return epsilon*x + (1-epsilon)*y\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/7455\n",
    "\n",
    "#  implementation of Label smoothing with NLLLoss and ignore_index\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon:float=0.1, reduction='mean',ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "    def forward(self, preds, target):\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = preds\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction,ignore_index=self.ignore_index)\n",
    "        return linear_combination(loss/n, nll, self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c9eef77-1500-48e1-873c-51677cb1f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922dbdff-f248-4969-9237-69cd2a58aa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nFrom clinical-GAN README:\\n\\n--epochs: Total number of epochs. Default=100\\n--gen_layers: Total number of generator's Encoder and Decoder layers. Default=3 \\n--disc_layers: Total number of discriminator's Encoder layers. Default=1\\n--dropout: Dropout value to be applied forreducing overfitting. Default=0.1\\n--alpha:alpha value for Generator's loss. Default=0.3\\n--gen_heads: Total number of multi-head in Generator. Default=8\\n--disc_heads:Total number of multi-head in Discriminator. Default=4.\\n--hid_dim: Embedding dimension of both Generator and discriminator. Default=256\\n--pf_dim: Hidden dimension of both Generator and discriminator. Default=512\\n--warmup_steps: warmp up steps for learning rate. Default=30\\n--labelSmoothing:label smoothing value for reducing overfitting. Default=0.0\\n--factor: factor by which the learning rate value should increase or decrease. Default=1\\n--checkpoint_dir: If you want to run the model for more epochs after terminating the training, Provide the path of the saved model. Default=None\\n\\n--learning_rate : learning rate of the model. Default=4e-4.\\n--batch_size : batch size to be used for training the model. Default=8\\n--clip: Discriminator's cliping value for gradient clipping. Default=0.1\\n--gen_clip:Generator's cliping value for gradient clipping. Default=1.0\\n\\n--valid_data_ratio:How much data should be allocated to valid set in percentage. Default=0.05\\n--test_data_ratio: How much data should be allocated to test set in percentage. Default=0.05\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "From clinical-GAN README:\n",
    "\n",
    "--epochs: Total number of epochs. Default=100\n",
    "--gen_layers: Total number of generator's Encoder and Decoder layers. Default=3 \n",
    "--disc_layers: Total number of discriminator's Encoder layers. Default=1\n",
    "--dropout: Dropout value to be applied forreducing overfitting. Default=0.1\n",
    "--alpha:alpha value for Generator's loss. Default=0.3\n",
    "--gen_heads: Total number of multi-head in Generator. Default=8\n",
    "--disc_heads:Total number of multi-head in Discriminator. Default=4.\n",
    "--hid_dim: Embedding dimension of both Generator and discriminator. Default=256\n",
    "--pf_dim: Hidden dimension of both Generator and discriminator. Default=512\n",
    "--warmup_steps: warmp up steps for learning rate. Default=30\n",
    "--labelSmoothing:label smoothing value for reducing overfitting. Default=0.0\n",
    "--factor: factor by which the learning rate value should increase or decrease. Default=1\n",
    "--checkpoint_dir: If you want to run the model for more epochs after terminating the training, Provide the path of the saved model. Default=None\n",
    "\n",
    "--learning_rate : learning rate of the model. Default=4e-4.\n",
    "--batch_size : batch size to be used for training the model. Default=8\n",
    "--clip: Discriminator's cliping value for gradient clipping. Default=0.1\n",
    "--gen_clip:Generator's cliping value for gradient clipping. Default=1.0\n",
    "\n",
    "--valid_data_ratio:How much data should be allocated to valid set in percentage. Default=0.05\n",
    "--test_data_ratio: How much data should be allocated to test set in percentage. Default=0.05\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c2954c-1e0d-4c1a-942f-575f9b3a963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bfa83d-0ddc-4803-a04e-3078fb92071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the embedding vecs\n",
    "SOURCE_VOCAB_SIZE = len(source_tokens_to_ids)\n",
    "TARGET_VOCAB_SIZE = len(target_tokens_to_ids)\n",
    "\n",
    "MAX_INPUT_LEN = 512\n",
    "MAX_OUT_LEN = 96\n",
    "\n",
    "SRC_PAD_ID = 0\n",
    "TARGET_PAD_ID = 0\n",
    "\n",
    "#AGNOSTIC\n",
    "DROPOUT = 0.1\n",
    "PF_DIM = 512\n",
    "\n",
    "# Optimizer, scheduler and loss Params\n",
    "LR = 4e-4\n",
    "WARMUP_STEPS = 30\n",
    "FACTOR = 1 # WTF!\n",
    "LABEL_SMOOTHING = 0.0 # WTF!\n",
    "\n",
    "\n",
    "# MODEL PARAMS\n",
    "# GEN\n",
    "N_HEAD_GEN = 8\n",
    "N_LAYERS_GEN = 3\n",
    "HID_DIM = 256\n",
    "\n",
    "# DISC\n",
    "N_LAYERS_DISC = 1\n",
    "N_HEAD_DISC = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd2e1b2-67b0-4511-bdf9-91bb6ede9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Models init\n",
    "enc = Encoder(input_dim=SOURCE_VOCAB_SIZE, hid_dim=HID_DIM, n_layers=N_LAYERS_GEN, n_heads=N_HEAD_GEN,\n",
    "              pf_dim=PF_DIM, dropout=DROPOUT, max_length=MAX_INPUT_LEN).to(device)\n",
    "\n",
    "dec = Decoder(output_dim=TARGET_VOCAB_SIZE, hid_dim=HID_DIM, n_layers=N_LAYERS_GEN,\n",
    "              n_heads=N_HEAD_GEN, pf_dim=PF_DIM, dropout=DROPOUT, max_length=MAX_OUT_LEN).to(device)\n",
    "\n",
    "gen = Generator(enc, dec, src_pad_idx=SRC_PAD_ID, trg_pad_idx=TARGET_PAD_ID).to(device)\n",
    "\n",
    "disc = Discriminator(input_dim=SOURCE_VOCAB_SIZE, hid_dim=HID_DIM, n_layers=N_LAYERS_DISC, n_heads=N_HEAD_DISC,\n",
    "                     pf_dim=PF_DIM, dropout=DROPOUT, src_pad_idx=SRC_PAD_ID, max_length= MAX_INPUT_LEN+MAX_OUT_LEN).to(device)\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr = LR)\n",
    "disc_opt = torch.optim.SGD(disc.parameters(), lr = LR)\n",
    "\n",
    "lr_schedulerG = NoamLR(gen_opt, warmup_steps=WARMUP_STEPS, factor=FACTOR, model_size=HID_DIM)\n",
    "lr_schedulerD = NoamLR(disc_opt, warmup_steps=WARMUP_STEPS, factor=FACTOR, model_size=HID_DIM)\n",
    "\n",
    "\n",
    "gen.apply(initialize_weights)\n",
    "disc.apply(initialize_weights)\n",
    "\n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(epsilon=LABEL_SMOOTHING, ignore_index=TARGET_PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2852ed5c-49e4-4cea-9c48-e30b37746bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "alpha = 0.3\n",
    "clip = 0.1\n",
    "gen_clip = 1\n",
    "\n",
    "crit_repeats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc7b109-9378-4a23-a32c-0199e69fe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "val_batch_size = 512\n",
    "\n",
    "trainLoader = DataLoader(train_dataset,\n",
    "                                  shuffle = True,\n",
    "                                  batch_size = train_batch_size,\n",
    "                                  num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                                  pin_memory = True,\n",
    "                                  collate_fn = custom_collate_fn)\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "                            shuffle = False,\n",
    "                            batch_size = val_batch_size,\n",
    "                            num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                            pin_memory = True,\n",
    "                            collate_fn = custom_collate_fn)\n",
    "\n",
    "\n",
    "testLoader = DataLoader(test_dataset,\n",
    "                             shuffle = False,\n",
    "                             batch_size = 1,\n",
    "                             num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                             pin_memory = True,\n",
    "                             collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e448184-28a2-42c3-a167-ab623ef4b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(pair):\n",
    "    pair.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    inp_batch, output_batch = [],[]\n",
    "    for pair in pair:\n",
    "        inp_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp= padVar(inp_batch).permute(1,0)\n",
    "    output = padVar(output_batch).permute(1,0)\n",
    "    return inp,output\n",
    "\n",
    "def padVar(inp_batch):\n",
    "    padList = list(itertools.zip_longest(*inp_batch, fillvalue=0))\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc415b67-9ff4-4b61-93a8-9639780a12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinrealData(pair):\n",
    "    data = []\n",
    "    #print(f\"pair : {pair} \")\n",
    "       \n",
    "    for pair in pair:\n",
    "        data.append(pair[0][:-1]+pair[1][1:])\n",
    "            \n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    return padVar(data).permute(1,0)\n",
    "\n",
    "def joinfakeData(pair,output):\n",
    "    data = []\n",
    "    #print(f\"pair : {pair , len(pair)} output = {output, type(output) , len(output) } \")\n",
    "\n",
    "    for i in range(len(pair)):\n",
    "        #print(f\"iteration : {i} \\n X : {pair[i][0][:-1]} \\n Yhat: {output[i]}\")\n",
    "        data.append(pair[i][0][:-1] + output[i])\n",
    "\n",
    "            \n",
    "    data.sort(key=lambda x: len(x), reverse=True)\n",
    "    return padVar(data).permute(1,0)\n",
    "\n",
    "\n",
    "def convertOutput(pair,reverseOutTypes):\n",
    "    newPair = []\n",
    "    for pair in pair:\n",
    "        newOutput = []\n",
    "        for code in pair[1]:\n",
    "            newOutput.append(reverseOutTypes[code])\n",
    "        newPair.append((pair[0],newOutput))\n",
    "    return newPair\n",
    "        \n",
    "def convertGenOutput(output,reverseOutTypes):\n",
    "    newOutputs = []\n",
    "    for codes in output:\n",
    "        newOutput = []\n",
    "        for code in codes:\n",
    "            #print(f\" code :{code} output: {output}\")\n",
    "            newOutput.append(reverseOutTypes[code])\n",
    "        newOutputs.append(newOutput)\n",
    "        \n",
    "    return newOutputs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f9d214-8f0b-4338-ad0d-6ce622e824bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad(src: torch.Tensor, trg:torch.Tensor) -> Tuple[List,List] :\n",
    "    sources, targets = [],[]\n",
    "    for i in range(src.size(0)): # i.e iter through batch size\n",
    "        sources.append(src[i][src[i]!=0].tolist())\n",
    "        targets.append(trg[i][trg[i]!=0].tolist())\n",
    "    return list(zip(sources, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15270140-7232-4098-b79c-58ba5d851e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(crit_fake_pred):\n",
    "    #print(\"crit_fake_pred shape\",crit_fake_pred.shape)\n",
    "    gen_loss = -1. * torch.mean(crit_fake_pred)\n",
    "    return gen_loss\n",
    "\n",
    "\n",
    "def get_crit_loss(crit_fake_pred, crit_real_pred):\n",
    "\n",
    "    crit_loss =  (-1* torch.mean(crit_fake_pred)) - (-1* torch.mean(crit_real_pred))\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539b6f8e-922c-4dca-8dba-606f4e959b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, Loader, criterion,device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in Loader:\n",
    "            src,trg = batch['source_sequences'].to(device),batch['target_sequences'].to(device)\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48343792-a33d-4c12-875c-d17cdd696974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClinicalGAN.pth\n"
     ]
    }
   ],
   "source": [
    "ls clinical_trash_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3469da-8b3a-4dce-85a9-4f5e09708626",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"clincal_checkpoint\",\"ClinicalGAN.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b8997a2-9aac-4a87-9784-9f86a31d9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_src_mask(src_pad_idx, src):\n",
    "\n",
    "    src_mask = (src != src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    return src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb485c0c-e3b9-43d8-984b-17b67e599d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b56238-ba24-4dfd-a9d1-1fc15cc98fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='training_clincal.log',\n",
    "    filemode='a',  # Append mode\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5e192-f691-46ec-bfcf-0fc949b8d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('test')\n",
    "logging.info('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ade61a-5018-46c5-84b1-11af43881451",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "vLoss = []\n",
    "tLoss = []\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    totalGen = 0\n",
    "    totalDis = 0\n",
    "    epoch_loss = 0\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    lr_schedulerG.step()\n",
    "    lr_schedulerD.step()\n",
    "    for batch in tqdm(trainLoader):\n",
    "        #innerCount = 0 \n",
    "        #print(batch_size)\n",
    "        src, trg = batch['source_sequences'].to(device),batch['target_sequences'].to(device)\n",
    "        ## Update discriminator ##\n",
    "        DisLoss =0\n",
    "        for _ in range(crit_repeats):\n",
    "            disc_opt.zero_grad()\n",
    "            output, _ = gen(src, trg[:,:-1]) # encoder-decoder returns output, attention\n",
    "            _,predValues = torch.max(output,2) \n",
    "            # make the input and target sequences have the same codification for the same medical codes\n",
    "            pair = unpad(src,trg)\n",
    "            real = joinrealData(convertOutput(pair,reverseOutTypes)) \n",
    "            fake = joinfakeData(pair,convertGenOutput(predValues.tolist(),reverseOutTypes))\n",
    "            #print(f\"real : {real.shape} \\n fake : {fake.shape}  \\n predValues:{predValues}\")\n",
    "            fake_mask =  make_src_mask(0, fake)\n",
    "            real_mask = make_src_mask(0, real)\n",
    "            real, fake, fake_mask, real_mask = real.to(device), fake.to(device) , fake_mask.to(device), real_mask.to(device)\n",
    "\n",
    "            crit_fake_pred = disc(fake,fake_mask)\n",
    "            crit_real_pred = disc(real, real_mask)\n",
    "            disc_loss = get_crit_loss(crit_fake_pred, crit_real_pred)\n",
    "            DisLoss += disc_loss.item()/crit_repeats\n",
    "            disc_loss.backward(retain_graph=True)\n",
    "            disc_opt.step()\n",
    "\n",
    "            for parameters in disc.parameters():\n",
    "                parameters.data.clamp_(-clip, clip)\n",
    "                \n",
    "        totalDis += DisLoss\n",
    "        ## Update generator ##\n",
    "        gen_opt.zero_grad()\n",
    "        output, _ = gen(src, trg[:,:-1])\n",
    "        _,predValues = torch.max(output,2)\n",
    "        fake = joinfakeData(pair,convertGenOutput(predValues.tolist(),reverseOutTypes))\n",
    "        fake_mask = make_src_mask(0, fake)\n",
    "        fake, fake_mask =fake.to(device) , fake_mask.to(device)\n",
    "        #print(f\"gen training fake :{predValues}\")\n",
    "        disc_fake_pred = disc(fake,fake_mask)\n",
    "        gen_loss1 = get_gen_loss(disc_fake_pred)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trgs = trg[:,1:].contiguous().view(-1)\n",
    "\n",
    "        gen_loss2 = criterion(output,trgs)\n",
    "        gen_loss = (alpha * gen_loss1)  +  gen_loss2\n",
    "        totalGen += gen_loss.item()\n",
    "        gen_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gen.parameters(), gen_clip)\n",
    "        gen_opt.step()\n",
    "        #epoch_loss = gen_loss.item() + disc_loss.item()\n",
    "    \n",
    "    valid_loss = evaluate(gen, valLoader, criterion,device)\n",
    "    vLoss.append(valid_loss)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        # storing the  model which has the least validation loss\n",
    "        torch.save({'gen_state_dict': gen.state_dict(),\n",
    "            'disc_state_dict': disc.state_dict(),\n",
    "            'gen_optimizer_state_dict': gen_opt.state_dict(),\n",
    "            'disc_optimizer_state_dict': disc_opt.state_dict(),\n",
    "            'lr':lr_schedulerG.get_last_lr()[0],\n",
    "            'tLoss':tLoss,\n",
    "            'vLoss':vLoss}, path)\n",
    "        print('new best at epoch', epoch)\n",
    "        logging.info(f'New best at epoch {epoch}')\n",
    "                \n",
    "    tLoss.append(totalGen/len(trainLoader))\n",
    "    epoch_loss = totalDis + totalGen\n",
    "    \n",
    "\n",
    "    print(f'current learning rate : {lr_schedulerG.get_last_lr()}')\n",
    "    #print(f'current learning rate Discriminator : {lr_schedulerD.get_last_lr()}')\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f\" Train loss {totalGen/len(trainLoader)} , validation loss :{valid_loss}\")\n",
    "    logging.info(f'Current learning rate: {lr_schedulerG.get_last_lr()}')\n",
    "    logging.info(f'Epoch: {epoch + 1:02}')\n",
    "    logging.info(f'Train loss: {totalGen / len(trainLoader)}, Validation loss: {valid_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d54dc3ea-777d-4e44-acc9-9c9deac0da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trg_mask(trg,trg_pad_idx,device):\n",
    "\n",
    "    trg_pad_mask = (trg != trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    trg_len = trg.shape[1]\n",
    "    \n",
    "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()\n",
    "    trg_mask = trg_pad_mask & trg_sub_mask\n",
    "    return trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d3db77-d588-44a3-bb3e-c64fb77966d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = os.path.join(\"clinical_script\",\"ClinicalGAN.pth\")\n",
    "\n",
    "enc = Encoder(input_dim=SOURCE_VOCAB_SIZE, hid_dim=HID_DIM, n_layers=N_LAYERS_GEN, n_heads=N_HEAD_GEN,\n",
    "              pf_dim=PF_DIM, dropout=DROPOUT, max_length=MAX_INPUT_LEN).to(device)\n",
    "\n",
    "dec = Decoder(output_dim=TARGET_VOCAB_SIZE, hid_dim=HID_DIM, n_layers=N_LAYERS_GEN,\n",
    "              n_heads=N_HEAD_GEN, pf_dim=PF_DIM, dropout=DROPOUT, max_length=MAX_OUT_LEN).to(device)\n",
    "\n",
    "gen = Generator(enc, dec, src_pad_idx=SRC_PAD_ID, trg_pad_idx=TARGET_PAD_ID).to(device)\n",
    "\n",
    "checkpoint = torch.load(test_path)\n",
    "gen.load_state_dict(checkpoint['gen_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfebece1-83f6-465a-94c2-113e687faef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(tgt_seq_len, DEVICE='cuda:0'):\n",
    "    \"\"\"\n",
    "    Generates a square subsequent mask for self-attention mechanism.\n",
    "\n",
    "    Args:\n",
    "        sz (int): The size of the mask.\n",
    "        DEVICE (str, optional): The device to be used for computation. Defaults to 'cuda:0'.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The square subsequent mask.\n",
    "\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948fd7f-213f-4216-b59d-97a9d6fda7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63238537-fe6c-4c26-8b86-2b23a970124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(model, dataloader : torch.utils.data.dataloader.DataLoader,  source_pad_id : int = 0,\n",
    "                   tgt_tokens_to_ids : Dict[str, int] =  None, max_len : int = 150,  DEVICE : str ='cuda:0'):\n",
    "    \"\"\"\n",
    "    return relevant forcasted and sequences made by the model on the dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be evaluated.\n",
    "        val_dataloader (torch.utils.data.DataLoader): The validation dataloader.\n",
    "        source_pad_id (int, optional): The padding token ID for the source input. Defaults to 0.\n",
    "        DEVICE (str, optional): The device to run the evaluation on. Defaults to 'cuda:0'.\n",
    "        tgt_tokens_to_ids (dict, optional): A dictionary mapping target tokens to their IDs. Defaults to None.\n",
    "        max_len (int, optional): The maximum length of the generated target sequence. Defaults to 100.\n",
    "    Returns:\n",
    "        List[List[int]], List[List[int]]: The list of relevant and forecasted sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    pred_trgs = []\n",
    "    targets = []\n",
    "    with torch.inference_mode():\n",
    "        for source_input_ids, target_input_ids in tqdm(dataloader, desc='scoring'):\n",
    "            batch_pred_trgs = []\n",
    "            batch_targets = []\n",
    "            source_input_ids, target_input_ids = source_input_ids.to(DEVICE),target_input_ids.to(DEVICE)\n",
    "            src_mask, source_padding_mask = create_source_mask(source_input_ids, source_pad_id, DEVICE) \n",
    "            enc_src = model.encode(source_input_ids, src_mask)\n",
    "            pred_trg = torch.tensor(tgt_tokens_to_ids['BOS'], device= DEVICE).repeat(source_input_ids.size(0)).unsqueeze(1)\n",
    "            # generate target sequence one token at a time at batch level\n",
    "            for i in range(max_len):\n",
    "                trg_mask = generate_square_subsequent_mask(i+1, DEVICE)\n",
    "                output, attention,_ = model.decoder(pred_trg, enc_src, trg_mask, src_mask)\n",
    "                pred_tokens = torch.argmax(output, dim=1)\n",
    "                return output\n",
    "                pred_trg = torch.cat((pred_trg, pred_tokens.unsqueeze(1)), dim=1)\n",
    "                eov_mask = pred_tokens == tgt_tokens_to_ids['EOV']\n",
    "\n",
    "                if eov_mask.any():\n",
    "                    # extend with sequences that have reached EOV\n",
    "                    batch_pred_trgs.extend(pred_trg[eov_mask].tolist())\n",
    "                    batch_targets.extend(target_input_ids[eov_mask].tolist())\n",
    "                    # break if all have reached EOV\n",
    "                    if eov_mask.all():\n",
    "                        break  \n",
    "                    # edit corresponding target sequences\n",
    "                    target_input_ids = target_input_ids[~eov_mask]\n",
    "                    pred_trg = pred_trg[~eov_mask]\n",
    "                    memory = memory[~eov_mask]\n",
    "        \n",
    "            # add elements that have never reached EOV\n",
    "            if source_input_ids.size(0) != len(batch_pred_trgs):\n",
    "                batch_pred_trgs.extend(pred_trg.tolist())\n",
    "                batch_targets.extend(target_input_ids.tolist())\n",
    "            pred_trgs.extend(batch_pred_trgs)\n",
    "            targets.extend(batch_targets)\n",
    "    return pred_trgs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f6853-8a98-49cb-8ef2-ef801342079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateGAN(model,Loader,types,max_len,device):\n",
    "    \n",
    "    model.eval()\n",
    "    pred_trgs = []\n",
    "    trgs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(Loader):\n",
    "            \n",
    "            src, trg =  batch['source_sequences'].to(device),batch['target_sequences'].to(device)\n",
    "            \n",
    "            src_mask = make_src_mask(src,types['PAD'])\n",
    "            enc_src = model.encoder(src, src_mask)\n",
    "            \n",
    "            pred_trg = [types['BOS']]\n",
    "            for i in range(max_len):\n",
    "                trg_tensor = torch.LongTensor(pred_trg).unsqueeze(0).to(device)\n",
    "                trg_mask = make_trg_mask(trg_tensor,types['PAD'],device)\n",
    "                output, attention,_ = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "                output = output.squeeze(0)\n",
    "                _,pred_token = torch.max(output,1)\n",
    "                pred_token = pred_token[-1] # \n",
    "                \n",
    "                pred_trg.append(pred_token.item())\n",
    "                \n",
    "                if pred_token == types['EOV']:\n",
    "                    break\n",
    "\n",
    "            trg = [code for code in trg]\n",
    "            pred_trgs.append(pred_trg)\n",
    "            trgs.append(trg)\n",
    "            \n",
    "        return pred_trgs, trgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7079e03e-5517-43a6-824a-5d0bcf2a6a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7461/7461 [06:53<00:00, 18.04it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_trgs, trgs = evaluateGAN(gen, testLoader, target_tokens_to_ids, 96, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04cf6892-2265-43dc-a0c5-99cfc40d5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x[0].tolist() for x in trgs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21260f6f-2c05-44b4-a325-1701ebc84010",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = DataLoader(test_dataset,\n",
    "                             shuffle = False,\n",
    "                             batch_size = 1, # Requires batch size = 1\n",
    "                             num_workers = int(os.environ[\"SLURM_CPUS_PER_TASK\"]),\n",
    "                             pin_memory = True,\n",
    "                             collate_fn = custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f3dccc-b717-4846-b0b3-6aa07a7830d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sifal.klioui/PatientTrajectoryForecasting\n"
     ]
    }
   ],
   "source": [
    "cd PatientTrajectoryForecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6197224e-09da-4f20-b166-1120d80ed9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval import mapk, recallTop\n",
    "ks  = [20, 40, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e80bd3ce-082a-41d6-8039-54aadab37404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_map@20: 0.5487256213895039, test_map@40: 0.5506449931495279, test_map@60: 0.5505969784255944, test_recall@20: 0.4164792624185335, test_recall@40: 0.4202416091755821, test_recall@60: 0.4204064166619706\n"
     ]
    }
   ],
   "source": [
    "test_mapk = {f\"test_map@{k}\": mapk(targets, pred_trgs, k) for k in ks}\n",
    "test_recallk = {f\"test_recall@{k}\": recallTop(targets, pred_trgs, rank = [k])[0] for k in ks}\n",
    "print(f'test_map@20: {test_mapk[\"test_map@20\"]}, test_map@40: {test_mapk[\"test_map@40\"]}, test_map@60: {test_mapk[\"test_map@60\"]}, test_recall@20: {test_recallk[\"test_recall@20\"]}, test_recall@40: {test_recallk[\"test_recall@40\"]}, test_recall@60: {test_recallk[\"test_recall@60\"]}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ea0be-8e6a-4084-ae4f-58b0a3fea68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dude",
   "language": "python",
   "name": "mimibert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
