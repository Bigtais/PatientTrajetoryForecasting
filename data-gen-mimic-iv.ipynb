{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1aa5f799-237c-4e5b-9d14-77f82fc98378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebooks is an attempt to port the code form https://github.com/MostHumble/Clinical-GAN/blob/master/process_data.py \n",
    "# to a more recent mimic dataset version\n",
    "# while adding suitable updates that weren't taken into account: for now mailnly scheduled to work on stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6abc67-8c82-4935-8f76-ec08b074a85a",
   "metadata": {},
   "source": [
    "# Done porting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad943fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "import gzip\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "#parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a1c23b-86ee-4843-872d-f0af867ab682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions.csv.gz\t emar_detail.csv.gz\t    poe_detail.csv.gz\n",
      "d_hcpcs.csv.gz\t\t hcpcsevents.csv.gz\t    prescriptions.csv.gz\n",
      "diagnoses_icd.csv.gz\t labevents.csv.gz\t    procedures_icd.csv.gz\n",
      "d_icd_diagnoses.csv.gz\t microbiologyevents.csv.gz  provider.csv.gz\n",
      "d_icd_procedures.csv.gz  omr.csv.gz\t\t    services.csv.gz\n",
      "d_labitems.csv.gz\t patients.csv.gz\t    transfers.csv.gz\n",
      "drgcodes.csv.gz\t\t pharmacy.csv.gz\n",
      "emar.csv.gz\t\t poe.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls mimic-iv-2.2/hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b43c66-facc-4071-87e3-d6fde9f2cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_path = 'mimic-iv-2.2/hosp'\n",
    "CCSRDX_file = 'DXCCSR_v2021-2/DXCCSR_v2021-2.csv'\n",
    "CCSRPCS_file = 'PRCCSR_v2021-1/PRCCSR_v2021-1.csv'\n",
    "#os.path.join(mimic_iv_path, 'ADMISSIONS.csv')\n",
    "admissionFile = os.path.join(mimic_iv_path, 'admissions.csv.gz')\n",
    "diagnosisFile = os.path.join(mimic_iv_path, 'diagnoses_icd.csv.gz')\n",
    "procedureFile = os.path.join(mimic_iv_path, 'procedures_icd.csv.gz')\n",
    "#patientsAge = os.path.join(mimic_iv_path, 'patientsAge.csv')\n",
    "prescriptionFile = os.path.join(mimic_iv_path, 'prescriptions.csv.gz')\n",
    "#diagnosisFrequencyFile = os.path.join(mimic_iv_path, 'WITHOUT_IF_CODE_COUNT.csv')\n",
    "#outFile = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d21e802-6b27-4756-a628-8809fae1c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = pd.read_csv(admissionFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d99f82-8c2f-48a4-b6d4-c01196f810ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admit_provider_id</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>P874LG</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Other</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-05-06 19:17:00</td>\n",
       "      <td>2180-05-06 23:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-26 18:27:00</td>\n",
       "      <td>2180-06-27 18:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P09Q6Y</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>2180-06-26 21:31:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P60CC5</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOSPICE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>2180-08-06 01:44:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P30KEH</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000068</td>\n",
       "      <td>25022803</td>\n",
       "      <td>2160-03-03 23:16:00</td>\n",
       "      <td>2160-03-04 06:26:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>P51VDL</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2160-03-03 21:55:00</td>\n",
       "      <td>2160-03-04 06:26:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            admittime            dischtime deathtime  \\\n",
       "0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00       NaN   \n",
       "1    10000032  22841357  2180-06-26 18:27:00  2180-06-27 18:49:00       NaN   \n",
       "2    10000032  25742920  2180-08-05 23:44:00  2180-08-07 17:50:00       NaN   \n",
       "3    10000032  29079034  2180-07-23 12:35:00  2180-07-25 17:55:00       NaN   \n",
       "4    10000068  25022803  2160-03-03 23:16:00  2160-03-04 06:26:00       NaN   \n",
       "\n",
       "   admission_type admit_provider_id      admission_location  \\\n",
       "0          URGENT            P874LG  TRANSFER FROM HOSPITAL   \n",
       "1        EW EMER.            P09Q6Y          EMERGENCY ROOM   \n",
       "2        EW EMER.            P60CC5          EMERGENCY ROOM   \n",
       "3        EW EMER.            P30KEH          EMERGENCY ROOM   \n",
       "4  EU OBSERVATION            P51VDL          EMERGENCY ROOM   \n",
       "\n",
       "  discharge_location insurance language marital_status   race  \\\n",
       "0               HOME     Other  ENGLISH        WIDOWED  WHITE   \n",
       "1               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "2            HOSPICE  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "3               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "4                NaN     Other  ENGLISH         SINGLE  WHITE   \n",
       "\n",
       "             edregtime            edouttime  hospital_expire_flag  \n",
       "0  2180-05-06 19:17:00  2180-05-06 23:30:00                     0  \n",
       "1  2180-06-26 15:54:00  2180-06-26 21:31:00                     0  \n",
       "2  2180-08-05 20:58:00  2180-08-06 01:44:00                     0  \n",
       "3  2180-07-23 05:54:00  2180-07-23 14:00:00                     0  \n",
       "4  2160-03-03 21:55:00  2160-03-04 06:26:00                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619231a0-7d44-4524-9891-48a2fdb1aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_icd(code: str, version: int, is_diag: bool) -> str:\n",
    "    \"\"\"format icd code depending on version\"\"\"\n",
    "    if version == 9:\n",
    "        return reformat_icd9(code, is_diag)\n",
    "    elif version == 10:\n",
    "        return reformat_icd10(code, is_diag)\n",
    "    else:\n",
    "        raise ValueError(\"version must be 9 or 10\")\n",
    "\n",
    "def reformat_icd10(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "    Generally, procedure codes have dots after the first two digits,\n",
    "    while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if not is_diag:\n",
    "        return code\n",
    "    return code[:3] + \".\" + code[3:]\n",
    "\n",
    "\n",
    "def reformat_icd9(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "    Generally, procedure codes have dots after the first two digits,\n",
    "    while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if is_diag:\n",
    "        if code.startswith(\"E\"):\n",
    "            if len(code) > 4:\n",
    "                return code[:4] + \".\" + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                return code[:3] + \".\" + code[3:]\n",
    "    else:\n",
    "        if len(code) > 2:\n",
    "            return code[:2] + \".\" + code[2:]\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b553c9-23bd-4a80-bd28-ea23ff7fb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ICDs_from_mimic_file(fileName ,isdiagnosis=True):\n",
    "    \n",
    "    mapping = {}\n",
    "    mimicFile = gzip.open(fileName, 'r')\n",
    "        \n",
    "    codes = []\n",
    "    \n",
    "    number_of_null_ICD9_codes = 0\n",
    "    number_of_null_ICD10_codes = 0\n",
    "    mimicFile.readline()\n",
    "    for line in mimicFile:  #   0  ,     1    ,    2   ,   3  ,    4\n",
    "        tokens = line.decode('utf-8').strip().split(',')\n",
    "        #print(tokens)\n",
    "        hadm_id = int(tokens[1])\n",
    "        if ( isdiagnosis and len(tokens[3]) == 0) or ( not(isdiagnosis) and len(tokens[4]) == 0 ):\n",
    "            if isdiagnosis:\n",
    "                if (tokens[4] =='9'):\n",
    "                    # ignore diagnoses where ICD9_code is null\n",
    "                    number_of_null_ICD9_codes += 1\n",
    "                else:\n",
    "                    number_of_null_ICD10_codes += 1\n",
    "\n",
    "                continue;\n",
    "            else:\n",
    "                if (tokens[5] =='9'):\n",
    "                    # ignore diagnoses where ICD9_code is null\n",
    "                    number_of_null_ICD9_codes += 1\n",
    "                else:\n",
    "                    number_of_null_ICD10_codes += 1\n",
    "\n",
    "                continue;\n",
    "                \n",
    "        if isdiagnosis:\n",
    "            ICD_code = tokens[3]\n",
    "        else:\n",
    "            ICD_code = tokens[4] \n",
    "            \n",
    "            \n",
    "        if ICD_code.find(\"\\\"\") != -1:\n",
    "            #print(\"ICD_Code before\",ICD_code )\n",
    "            ICD_code = ICD_code[1:-1].strip()  # toss off quotes and proceed\n",
    "            #print(\"ICD_Code after\",ICD_code )\n",
    "        # since diagnosis and procedure ICD9 codes have intersections, a prefix is necessary for disambiguation\n",
    "       \n",
    "        if isdiagnosis:\n",
    "            ICD_code = 'D' + tokens[4]+ '_' +ICD_code\n",
    "        else:\n",
    "            ICD_code = 'P' + tokens[5] + '_' + ICD_code\n",
    "\n",
    "        # To understand the line below, check https://mimic.physionet.org/mimictables/diagnoses_icd/\n",
    "        # \"The code field for the ICD-9-CM Principal and Other Diagnosis Codes is six characters in length (not really!),\n",
    "        # with the decimal point implied between the third and fourth digit for all diagnosis codes other than the V codes.\n",
    "        # The decimal is implied for V codes between the second and third digit.\"\n",
    "        # Actually, if you look at the codes (https://raw.githubusercontent.com/drobbins/ICD9/master/ICD9.txt), simply take the three first characters\n",
    "        #if not map_ICD9_to_CCS:\n",
    "          #  ICD_code = ICD_code[:4]  # No CCS mapping, get the first alphanumeric four letters only\n",
    "\n",
    "\n",
    "        if hadm_id in mapping:\n",
    "            mapping[hadm_id].append(ICD_code.strip())\n",
    "        else:\n",
    "            mapping[hadm_id]= [ICD_code.strip()]  \n",
    "    mimicFile.close()\n",
    "    print ('-Number of null ICD9 codes in file ' + fileName + ': ' + str(number_of_null_ICD9_codes))\n",
    "    print ('-Number of null ICD10 codes in file ' + fileName + ': ' + str(number_of_null_ICD10_codes))\n",
    "    #print ('-Number of diagnosis codes in file ' + fileName + ': ' + str(len(codes)))\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9342d066-8192-4a4b-a783-9972c30b3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drugs_from_mimic_file(fileName, choice ='ndc'):\n",
    "    \"\"\"\n",
    "    This creates a hospital to list of drugs mapping and a drug to description ( name ) map\n",
    "    \n",
    "    inputs:\n",
    "    fileNAME : path to the procedure file\n",
    "    choice : drug codification to choose from\n",
    "    \n",
    "    outputs:\n",
    "    drugDescription : dict that maps drug codes to their name\n",
    "    mapping : dict that maps hospital admissions to a list of ndc/gsn drug codes\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    drugDescription = {}\n",
    "    mimicFile = gzip.open(fileName, 'r')  # subject_id,hadm_id,gsn,ndc,drug\n",
    "    mimicFile.readline()\n",
    "    number_of_null_NDC_codes = 0\n",
    "    try:\n",
    "        for line in mimicFile:\n",
    "            #print(line)#   0  ,     1    ,    2   ,   3  ,    4\n",
    "            #break\n",
    "            tokens = line.decode('utf-8').strip().split(',')\n",
    "            #print(tokens)\n",
    "            hadm_id = int(tokens[1])\n",
    "            if choice =='ndc':                        #code : Total Number of NDC code 5912\n",
    "                drug_code = tokens[12]   \n",
    "            else:    \n",
    "                drug_code = tokens[11]                    #code : Total Number of gsn code 3081\n",
    "\n",
    "            drug_code = drug_code.strip()  \n",
    "\n",
    "            drug_code = 'DR'+'_'+drug_code\n",
    "            if hadm_id in mapping:\n",
    "                mapping[hadm_id].append(drug_code.strip())\n",
    "            else:\n",
    "                #mapping[hadm_id]=set()           #use set to avoid repetitions\n",
    "                #mapping[hadm_id].add(drug_code.strip())\n",
    "                mapping[hadm_id]=[drug_code.strip()]\n",
    "                \n",
    "            if drug_code not in drugDescription:\n",
    "                drugDescription[drug_code] = tokens[9]\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(line)\n",
    "        print(e)\n",
    "    #for hadm_id in mapping.keys():\n",
    "        #mapping[hadm_id] = list(mapping[hadm_id])   #convert to list, as the rest of the codes expects\n",
    "    mimicFile.close()\n",
    "    return drugDescription, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6ba2f3-d66b-4a5e-ab29-45b03844d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mimic_data(choice ='ndc'):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    choice : the type of drug description to choose \n",
    "    \n",
    "    output:\n",
    "    subject_idAdmMap : dict that maps subject ids to hostpital admissions\n",
    "    admDxMap : dict that maps hospital admission ids to a list of ICD-9/ICD-10 diagnosis codes\n",
    "    admPxMap : dict that maps hospital admission ids to a list of ICD-9/ICD-10 procedure codes\n",
    "    admDrugMap : dict that maps hospital admissions to a list of ndc/gsn drug codes\n",
    "    drugDescription : dict that maps drug codes to their name\n",
    "    \"\"\"\n",
    "    print ('Building subject_id-admission mapping, admission-date mapping')\n",
    "    previous_subject = 0\n",
    "    previous_admission = 0\n",
    "    subject_idAdmMap = {}\n",
    "    admDateMap = {}\n",
    "    subject_idStatic = {}   # adm type, Insurance , ethnicity , marital status\n",
    "    infd = gzip.open(admissionFile, 'r')\n",
    "    infd.readline()\n",
    "    for line in infd:\n",
    "        tokens = line.decode('utf-8').strip().split(',')\n",
    "        subject_id = int(tokens[0])\n",
    "        hadm_id = int(tokens[1])\n",
    "        #admTime = datetime.strptime(tokens[2], '%Y-%m-%d %H:%M:%S')\n",
    "        #admTime = tokens[3]\n",
    "        #admDateMap[hadm_id] = admTime\n",
    "        #subject_idStatic[subject_id] = [convert_binary_to_Int(tokens)]\n",
    "        if subject_id in subject_idAdmMap: \n",
    "            subject_idAdmMap[subject_id].add(hadm_id)\n",
    "        else: \n",
    "            subject_idAdmMap[subject_id] = set()\n",
    "            subject_idAdmMap[subject_id].add(hadm_id)\n",
    "    for subject_id in subject_idAdmMap.keys():\n",
    "        subject_idAdmMap[subject_id] = list(subject_idAdmMap[subject_id])  \n",
    "    infd.close()\n",
    "\n",
    "    print ('Building admission-diagnosis mapping')\n",
    "    admDxMap = get_ICDs_from_mimic_file(diagnosisFile)\n",
    "\n",
    "    print ('Building admission-procedure mapping')\n",
    "    admPxMap = get_ICDs_from_mimic_file(procedureFile, isdiagnosis=False)\n",
    "\n",
    "    print ('Building admission-drug mapping')\n",
    "    drugDescription, admDrugMap = get_drugs_from_mimic_file(prescriptionFile, choice)\n",
    "    return subject_idAdmMap,admDxMap,admPxMap,admDrugMap,drugDescription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e13c57-1f8a-484d-a690-70288bfc7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateAdmCodeList(subject_idAdmMap,admDxMap,admPxMap,admDrugMap):\n",
    "    \"\"\"\n",
    "    This function discards filtered subjects from the admission ids to procedure, diagnosis, and drug ICD code maps.\n",
    "    \n",
    "    inputs:\n",
    "    subject_idAdmMap : dict that maps subject ids to hostpital admissions\n",
    "    admDxMap : dict that maps hospital admission ids to a list of ICD-9/ICD-10 diagnosis codes\n",
    "    admPxMap : dict that maps hospital admission ids to a list of ICD-9/ICD-10 procedure codes\n",
    "    admDrugMap : dict that maps hospital admissions to a list of ndc/gsn drug codes\n",
    "    \n",
    "    outputs:\n",
    "    filtred dicts \n",
    "    \"\"\"\n",
    "    adDx = {}\n",
    "    adPx = {}\n",
    "    adDrug={}\n",
    "    for subject_id, admIdList in subject_idAdmMap.items():\n",
    "        for admId in admIdList:\n",
    "            adDx[admId] = admDxMap[admId]\n",
    "            adPx[admId] =admPxMap[admId]\n",
    "            #adAge[admId] = admAgeMap[admId]\n",
    "            adDrug[admId] =admDrugMap[admId]\n",
    "            \n",
    "    return adDx,adPx,adDrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f949ce20-8d88-413d-9c43-f00fec6446b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListAvgVisit(dic):\n",
    "    a =[len(intList) for k,intList in dic.items()]\n",
    "    return sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32fe91c-011f-4e64-acdd-4595ac616480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "def countCodes(*dicts):\n",
    "    all_values = [value for dic in dicts for value in dic.values()]\n",
    "    code_counts = Counter(code for sublist in all_values for code in sublist)\n",
    "    return len(code_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f2d20a-47b4-439f-ac01-141a8be23eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(pidAdmMap,admDxMap,admPxMap,admDrugMap):\n",
    "    print(f\" Total Number of patients {len(pidAdmMap)}\")\n",
    "    print(f\" Total Number of admissions {len(admDxMap)}\")\n",
    "    print(f\" Average number of admissions per patient {ListAvgVisit(pidAdmMap)}\")\n",
    "    print(f\" Total Number of diagnosis code {countCodes(admDxMap)}\")\n",
    "    print(f\" Total Number of procedure code {countCodes(admPxMap)}\")\n",
    "    print(f\" Total Number of drug code {countCodes(admDrugMap)}\")\n",
    "    print(f\" Total Number of codes {countCodes(admPxMap) +countCodes(admDxMap)+countCodes(admDrugMap) }\")\n",
    "    print(f\" average Number of procedure code per visit {ListAvgVisit(admPxMap)}\")\n",
    "    print(f\" average Number of diagnosis code per visit {ListAvgVisit(admDxMap)}\")\n",
    "    print(f\" average Number of Drug code per visit {ListAvgVisit(admDrugMap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8e7cdc1-e313-4429-97ec-33528cb879cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(subject_idAdmMap,admDxMap,admPxMap,admDrugMap, min_admissions_threshold = 2):\n",
    "    # removing the subject_id which are not present in diagnostic code but present in procedure and vice versa\n",
    "    print(\"Cleaning data...\")\n",
    "    subDelList = []\n",
    "\n",
    "    print(\"Removing patient records who does not have all three medical codes for an admission\")\n",
    "    for subject_id,hadm_ids in  subject_idAdmMap.items():\n",
    "        for hadm_id in hadm_ids:\n",
    "            if (hadm_id not in admDxMap.keys()):\n",
    "                subDelList.append(subject_id)\n",
    "            if (hadm_id not in admPxMap.keys()):\n",
    "                subDelList.append(subject_id)\n",
    "            if (hadm_id not in admDrugMap.keys()):\n",
    "                subDelList.append(subject_id)\n",
    "\n",
    "    subDelList = list(set(subDelList))       \n",
    "    #print(f\"Number of subject_ids to be deleted :{len(subDelList)} \")\n",
    "\n",
    "    for subject_id_to_rm in subDelList:\n",
    "        del subject_idAdmMap[subject_id_to_rm]\n",
    "\n",
    "    #print(f\"Number of subject_ids aftr cleaning :{len(subject_idAdmMap)} \")  \n",
    "            \n",
    "    adDx,adPx,adDrug=updateAdmCodeList(subject_idAdmMap,admDxMap,admPxMap,admDrugMap)\n",
    "\n",
    "    #display(subject_idAdmMap,adDx,adPx,adDrug)\n",
    "    # removing patient who made less than 2 admissions\n",
    "\n",
    "    print(f\"Removing patient who made less than {min_admissions_threshold} admissions\")\n",
    "    pidMap = {}\n",
    "    adm = []\n",
    "    subDelList=[]\n",
    "    subject_idAdmMap1 = subject_idAdmMap\n",
    "    for pid, admIdList in subject_idAdmMap.items():\n",
    "        if len(admIdList) < min_admissions_threshold:\n",
    "            subDelList.append(pid)\n",
    "            continue\n",
    "\n",
    "    for i in subDelList:\n",
    "        del subject_idAdmMap[i]  \n",
    "\n",
    "    adDx,adPx,adDrug=updateAdmCodeList(subject_idAdmMap,adDx,adPx,adDrug)   \n",
    "    display(subject_idAdmMap,adDx,adPx,adDrug)  \n",
    "    return subject_idAdmMap,adDx,adPx,adDrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c61c7e-e7bc-453d-b8ea-37272cd1bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CCS_CCSR_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file, dump = True):\n",
    "\n",
    "    # This part seem to create an ICD-10 Diagnosis, Procedures map to CCS token list? \n",
    "    df = pd.read_csv(CCSRDX_file)\n",
    "    a = df[[\"\\'ICD-10-CM CODE\\'\", \"\\'CCSR CATEGORY 1\\'\", \"\\'CCSR CATEGORY 2\\'\", \"\\'CCSR CATEGORY 3\\'\", \"\\'CCSR CATEGORY 4\\'\", \"\\'CCSR CATEGORY 5\\'\", \"\\'CCSR CATEGORY 6\\'\"]]\n",
    "\n",
    "    a = a.map(lambda x: str(x)[1:-1])\n",
    "\n",
    "    a = a.set_index(\"\\'ICD-10-CM CODE\\'\").T.to_dict('list')\n",
    "    # remove null values\n",
    "    for key, value in a.items():\n",
    "        newValue = []\n",
    "        value = list(filter(lambda x: x.strip(),value))\n",
    "        for value in value: # never seen this: value gets overwritten\n",
    "            newValue.append('D10_'+value)\n",
    "        a[key] =  newValue\n",
    "        \n",
    "    b={}\n",
    "    for key in a.keys():\n",
    "        new_key = 'D10_'+key \n",
    "        b[new_key] = a[key]\n",
    "\n",
    "    df = pd.read_csv(CCSRPCS_file, on_bad_lines = 'skip' )\n",
    "    df = df[[\"\\'ICD-10-PCS\\'\", \"\\'PRCCSR\\'\"]]\n",
    "    df = df.map(lambda x: str(x)[1:-1])\n",
    "    df = df.set_index(\"\\'ICD-10-PCS\\'\").T.to_dict('list')\n",
    "\n",
    "    for key, value in df.items():\n",
    "        newValue = []\n",
    "        value = list(filter(lambda x: x.strip(), value))\n",
    "        for value in value:\n",
    "            newValue.append('P10_'+value)\n",
    "        df[key] =  newValue\n",
    "        \n",
    "    for key in df.keys():\n",
    "        new_key = 'P10_'+key \n",
    "        b[new_key] = df[key]\n",
    "        \n",
    "    # ICD -9 diagnosis code and prescription to CCS\n",
    "    ccsTOdescription_Map = {}\n",
    "    #'ICD-9-CM CODE','CCS CATEGORY','CCS CATEGORY DESCRIPTION','ICD-9-CM CODE DESCRIPTION','OPTIONAL CCS CATEGORY','OPTIONAL CCS CATEGORY DESCRIPTION'\n",
    "    #dxref_ccs_file = open('Single_Level_CCS_2015/$dxref 2015.csv', 'r')\n",
    "    dxref_ccs_file = open(CCSDX_file, 'r')\n",
    "    dxref_ccs_file.readline() #note\n",
    "    dxref_ccs_file.readline() #header\n",
    "    dxref_ccs_file.readline() #null\n",
    "    for line in dxref_ccs_file:\n",
    "        tokens = line.strip().split(',')\n",
    "        # since diagnosis and procedure ICD9 codes have intersections, a prefix is necessary for disambiguation\n",
    "        b['D9_'+str(tokens[0][1:-1]).strip()] = 'D9_'+str(tokens[1][1:-1]).strip() #[1:-1] retira aspas\n",
    "        ccsTOdescription_Map['D9_'+str(tokens[1][1:-1]).strip()] = str(tokens[2][1:-1]).strip() #[1:-1] retira aspas\n",
    "    dxref_ccs_file.close()\n",
    "\n",
    "    dxprref_ccs_file = open(CCSPX_file, 'r')\n",
    "    dxprref_ccs_file.readline() #note\n",
    "    dxprref_ccs_file.readline() #header\n",
    "    dxprref_ccs_file.readline() #null\n",
    "    for line in dxprref_ccs_file:\n",
    "        tokens = line.strip().split(',')\n",
    "        #since diagnosis and procedure ICD9 codes have intersections, a prefix is necessary for disambiguation\n",
    "        b['P9_'+str(tokens[0][1:-1]).strip()] = 'P9_'+str(tokens[1][1:-1]).strip() #[1:-1] retira aspas\n",
    "        ccsTOdescription_Map['P9_'+str(tokens[1][1:-1]).strip()] = str(tokens[2][1:-1]).strip() #[1:-1] retira aspas\n",
    "    dxprref_ccs_file.close()\n",
    "\n",
    "    if dump:\n",
    "        pickle.dump(b, open('ICD_9_10_to_CSS', 'wb'), -1)\n",
    "        pickle.dump(ccsTOdescription_Map, open('ccs_to_description_dictionary', 'wb'), -1)\n",
    "    print ('Total ICD to ccs entries: ' + str(len(b)))\n",
    "    print( 'Total ccs codes/descriptions: ' + str(len(ccsTOdescription_Map)))\n",
    "\n",
    "    v1= []\n",
    "    for v in b.values():\n",
    "        for val in v:\n",
    "            \n",
    "            v1.append(val)\n",
    "    v1 = list(set(v1))\n",
    "    print(\"total number of unqiue codes(DIag + proc):\", len(v1))\n",
    "\n",
    "    return ccsTOdescription_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8adad64e-be25-4856-b1de-890da41939b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ccsr_description(filename, cat = 'Diag'):\n",
    "    if cat == 'Diag':\n",
    "        padStr = 'D10_'\n",
    "    else:\n",
    "        padStr = 'P10_'\n",
    "    df = pd.read_excel(filename, sheet_name=\"CCSR_Categories\", skiprows=1)\n",
    "    if type!='Diag':\n",
    "        df = df[:-1]\n",
    "    codeDescription = df[[\"CCSR Category\", \"CCSR Category Description\"]]\n",
    "    codeDescription = codeDescription.map(lambda x: padStr+str(x))\n",
    "    codeDescription = codeDescription.set_index(\"CCSR Category\").T.to_dict('list')\n",
    "    for key,value in codeDescription.items():\n",
    "        newValue = value[0][4:]\n",
    "        codeDescription[key] = newValue\n",
    "\n",
    "    return codeDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25cde15d-93ae-4b9b-87d5-aba022dda008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convValuestoList(codeDic):\n",
    "    for key, value in codeDic.items():\n",
    "        codeDic[key] =  [value]\n",
    "    return codeDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de3b056c-4171-4069-bf66-f4910b28062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ICD_to_CCSR(mapping):\n",
    "    icdTOCCS_Map = pickle.load(open('ICD_9_10_to_CSS','rb'))\n",
    "    CodesToInternalMap = {}\n",
    "    missingCodes = []\n",
    "    set_of_used_codes = set()\n",
    "    number_of_codes_missing = 0\n",
    "    countICD9=0\n",
    "    countICD10 =0\n",
    "    for (hadm_id, ICDs_List) in mapping.items():\n",
    "        for ICD in ICDs_List:\n",
    "            #print(ICD,type(ICD),len(ICD))\n",
    "            #while (len(ICD9) < 6): ICD9 += ' '  #pad right white spaces because the CCS mapping uses this pattern\n",
    "            if ICD.startswith('D10_'):\n",
    "                padStr = 'D10_'\n",
    "            elif ICD.startswith('D9_'):\n",
    "                padStr = 'D9_'\n",
    "            elif ICD.startswith('P10_'):\n",
    "                padStr = 'P10_'    \n",
    "            elif ICD.startswith('P9_'):\n",
    "                padStr = 'P9_'  \n",
    "            else:\n",
    "                print(\"Wrong coding format\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                CCS_code = icdTOCCS_Map[ICD]\n",
    "\n",
    "                if hadm_id in CodesToInternalMap:\n",
    "                    if(isinstance(CCS_code, str)): \n",
    "                        CodesToInternalMap[hadm_id].append(CCS_code)\n",
    "                    else:\n",
    "                        for code in CCS_code:\n",
    "                            CodesToInternalMap[hadm_id].append(code)\n",
    "                        \n",
    "                else:\n",
    "                    if(isinstance(CCS_code, str)): \n",
    "                        CodesToInternalMap[hadm_id] = [CCS_code]\n",
    "                    else:\n",
    "                        for i in range(len(CCS_code)):\n",
    "                            if i==0:\n",
    "                                CodesToInternalMap[hadm_id] = [CCS_code[i]]\n",
    "                            else:\n",
    "                                CodesToInternalMap[hadm_id].append(CCS_code[i])\n",
    "                                \n",
    "                            \n",
    "                set_of_used_codes.add(ICD)\n",
    "\n",
    "            except KeyError:\n",
    "                #print(f\"the mapping of {ICD} {hadm_id}\")\n",
    "                missingCodes.append(ICD)\n",
    "                #print(f\"the mapping of  is : {icdTOCCS_Map[ICD]}\")\n",
    "                number_of_codes_missing +=1\n",
    "                #print (str(sys.exc_info()[0]) + '  ' + str(ICD) + \". ICD9 code not found, please verify your ICD9 to CCS mapping before proceeding.\")\n",
    "\n",
    "\n",
    "            \n",
    "    print(f\"total number of ICD9 codes used {countICD9} and ICD10 codes: {countICD10}\")  \n",
    "    print ('-Total number (complete set) of ICD9+ICD10 codes (diag + proc): ' + str(len(set(icdTOCCS_Map.keys()))))\n",
    "    #print ('-Total number (complete set) of CCS codes (diag + proc): ' + str(len(set(icd9TOCCS_Map.values()))))\n",
    "    print ('-Total number of ICD codes actually used: ' + str(len(set_of_used_codes)))\n",
    "    print ('-Total number of ICD codes missing in the admissions list: ' , number_of_codes_missing)\n",
    "    #print(icd9TOCCS_Map)\n",
    "    \n",
    "    return CodesToInternalMap,missingCodes,set_of_used_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80baa3b5-15c4-4492-b478-77f82ee74859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCodeStats(adDx,adPx,adDrug):\n",
    "    print(f\" Total Number of diagnosis code {countCodes(adDx)}\")\n",
    "    print(f\" Total Number of procedure code {countCodes(adPx)}\")\n",
    "    print(f\" Total Number of drug code {countCodes(adDrug)}\")\n",
    "    print(f\" Total Number of unique  D,P codes {countCodes(adDx,adPx) }\")\n",
    "    print(f\" Total Number of all codes {countCodes(adDx,adPx,adDrug) }\")\n",
    "\n",
    "\n",
    "    print(f\" average Number of procedure code per visit {ListAvgVisit(adPx)}\")\n",
    "    print(f\" average Number of diagnosis code per visit {ListAvgVisit(adDx)}\")\n",
    "    print(f\" average Number of drug code per visit {ListAvgVisit(adDrug)}\")\n",
    "\n",
    "    print(f\" Min. and max. Number of diagnosis code per admission {minMaxCodes(adDx)}\")\n",
    "    print(f\" Min. and max. Number of procedure code  per admission{minMaxCodes(adPx)}\")\n",
    "    print(f\" Min. and max. Number of drug code  per admission {minMaxCodes(adDrug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f832216c-b02d-4551-8be8-f15d71afe6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxCodes(dic):\n",
    "    countCode = []\n",
    "    for codes in dic.values():\n",
    "        countCode.append(len(codes))    \n",
    "                \n",
    "    return min(countCode),max(countCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e1347c-30c8-4170-8520-51245dc2769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file,D_CCSR_Ref_file,P_CCSR_Ref_file,adDx,adPx,adDrug,drugDescription):\n",
    "    # creating mappint between all ICD codes to CCS and CCSR mapping\n",
    "    ccsTOdescription_Map = create_CCS_CCSR_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file)\n",
    "    # getting the description of all codes\n",
    "    DxcodeDescription = map_ccsr_description(D_CCSR_Ref_file)\n",
    "    PxcodeDescription = map_ccsr_description(P_CCSR_Ref_file, cat = 'Proc')\n",
    "    codeDescription ={**DxcodeDescription ,**PxcodeDescription }\n",
    "    codeDescription ={**codeDescription , **convValuestoList(ccsTOdescription_Map), **drugDescription}\n",
    "    # mapping diagnois codes\n",
    "    adDx,missingDxCodes,set_of_used_codes1 = map_ICD_to_CCSR(adDx)\n",
    "    # mapping procedure codes\n",
    "    print('here it should be working')\n",
    "    print(adPx[23384508])\n",
    "    print('---------------')\n",
    "    adPx,missingPxCodes,set_of_used_codes2 = map_ICD_to_CCSR(adPx)\n",
    "    print( 'P10_0QS604Z' in missingPxCodes)\n",
    "    codeDescription['SOH'] = 'Start of history'\n",
    "    codeDescription['EOH'] = 'End of history'\n",
    "    codeDescription['BOV'] = 'Beginning of visit'\n",
    "    codeDescription['EOV'] = 'End of visit'\n",
    "    codeDescription['BOS'] = 'Beginning of sequence'\n",
    "    codeDescription['PAD'] = 'Padding'\n",
    "    displayCodeStats(adDx,adPx,adDrug)\n",
    "    return adDx,adPx,codeDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a62ff81-85a8-4548-8f33-e07108809b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(adDx, adPx, adDrug, min_dxm, min_px, min_drg):\n",
    "    print(\"Trimming the diagnosis, procedure, and medication codes for each visit\")\n",
    "    \n",
    "    for admission, DiagCodes in adDx.items():\n",
    "        adDx[admission] = DiagCodes[:min_dx]\n",
    "        \n",
    "    for admission, ProcCodes in adPx.items():\n",
    "        adPx[admission] = ProcCodes[:min_px]\n",
    "        \n",
    "    for admission, DrugCodes in adDrug.items():\n",
    "        adDrug[admission] = DrugCodes[:min_drg]\n",
    "        \n",
    "    displayCodeStats(adDx, adPx, adDrug)\n",
    "    return adDx, adPx, adDrug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fd9d2be-cbbf-4e92-8146-ea6cd46007bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildData(subject_idAdmMap,adDx,adPx,adDrug, minVisits = 2):\n",
    "    \n",
    "    adPx, adDx, adDrug = map(lambda d: defaultdict(list, d), (adPx, adDx, adDrug)) # add default [] for missing values\n",
    "\n",
    "    print (f'Building admission-Visits mapping & filtering patients with less than {minVisits} ')\n",
    "    pidSeqMap = {}\n",
    "    \n",
    "    skipped = 0 \n",
    "    for subject_id, admIdList in subject_idAdmMap.items():\n",
    "        if len(admIdList) < minVisits: \n",
    "            skipped += 1\n",
    "            continue # skip patients with less than minVisits ( default 1 )\n",
    "        sortedList = [( adDx[admId], adPx[admId],adDrug[admId]) for admId in admIdList]\n",
    "        \n",
    "        pidSeqMap[subject_id] = sortedList\n",
    "        \n",
    "    adPx, adDx, adDrug = map(dict, (adPx, adDx, adDrug))  # remove default [] behavior to not break something\n",
    "\n",
    "    \n",
    "    print(f'{skipped} subjects were removed')\n",
    "    print ('Building subject-id, diagnosis,procedure,drugs mapping')\n",
    "    subject_ids = []\n",
    "    dates = []\n",
    "    seqs =[]\n",
    "    ages = []\n",
    "    for subject_id,visits in pidSeqMap.items():\n",
    "        subject_ids.append(subject_id)\n",
    "        diagnose = []\n",
    "        procedure = []\n",
    "        drugs = []\n",
    "        date = []\n",
    "        seq=[]\n",
    "        #age = []\n",
    "        for visit in visits:\n",
    "            #date.append(visit[0])\n",
    "            #age.append(visit[4])\n",
    "            #joined = [visit[4]] + visit[1] +visit[2]+visit[3]\n",
    "            joined = list(dict.fromkeys(chain.from_iterable(visit))) # dict.from keys used as an ordered set func\n",
    "            seq.append(joined)\n",
    "        #dates.append(date)\n",
    "        seqs.append(seq)\n",
    "        #ages.append(age)\n",
    "    \n",
    "    print ('Converting Strings Codes into unique integer, and making types')\n",
    "    types={}\n",
    "    newSeqs = []\n",
    "    for patient in seqs:\n",
    "        newPatient = []\n",
    "        #print(\"patient\",patient)\n",
    "        for visit in patient:\n",
    "            #print(\"vsit\",visit)\n",
    "            newVisit = []\n",
    "            for code in visit:\n",
    "                #print(\"code\",code)\n",
    "                if code in types:\n",
    "                    newVisit.append(types[code])\n",
    "                else:\n",
    "                    types[code] = len(types)\n",
    "                    newVisit.append(types[code])\n",
    "                    #print(\"newVisit\",newVisit)\n",
    "            newPatient.append(newVisit)\n",
    "        newSeqs.append(newPatient)\n",
    "    return newSeqs,types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daad9149-170b-413b-9ec3-87ab07ecb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListAvgVisitForRemoveCode(dic):\n",
    "    a =[len(intList) for intList in dic]\n",
    "    return sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4e95a03-95cf-4cab-8310-4beb68d7a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCode(currentSeqs, types, threshold=5):\n",
    "\n",
    "    print(ListAvgVisitForRemoveCode(currentSeqs))\n",
    "    \n",
    "    countCode = Counter()\n",
    "    \n",
    "    for visits in currentSeqs:\n",
    "        for visit in visits:\n",
    "            countCode.update(visit)\n",
    "            \n",
    "    codes = [key for key, value in countCode.items() if value <= threshold]\n",
    "    \n",
    "    print(f\" Total number of codes removed: {len(codes)}  \")\n",
    "    print(f\" Total number of  unique codes : {len(countCode)}  \")\n",
    "\n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "\n",
    "    # List of codes like : D9_660...\n",
    "    types = defaultdict(lambda: len(types), {\"PAD\": 0,\"BOH\":1 ,\"BOS\": 2, \"BOV\": 3, \"EOV\": 4, \"EOH\": 5})\n",
    "\n",
    "    # Recreates a new mapping while taking into consideration the removed tokens\n",
    "    updatedSeqs = [[[types[reverseTypes[code]] for code in visit if code not in codes] for visit in patient] for patient in currentSeqs]\n",
    "    \n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "\n",
    "    return updatedSeqs, dict(types), reverseTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cdd0d6f-53ea-46ad-87b1-b0711a38913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFiles(updatedSeqs,types,codeDescription,outpath = 'outputData/originalData'):\n",
    "\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    pickle.dump(updatedSeqs, open(outFile+'.seqs', 'wb'), -1)\n",
    "    pickle.dump(types, open(outFile+'.types', 'wb'), -1)\n",
    "    pickle.dump(codeDescription, open(outFile+'.description', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f417c2d9-09d2-46fe-b680-2ed4ef8c4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCodeTypes(outFile,reverseTypes):\n",
    "    ICD_9_10_to_CSS = pickle.load(open('ICD_9_10_to_CSS','rb'))\n",
    "    codeType = {}\n",
    "    countD = 0\n",
    "    countP=0\n",
    "    countDr =0\n",
    "    countT =0\n",
    "    for keys,values in reverseTypes.items():\n",
    "        found =0\n",
    "        if keys not in codeType:\n",
    "            if values.startswith('DR_'):\n",
    "                found =1        \n",
    "                codeType[keys] ='DR'\n",
    "                countDr= countDr+1\n",
    "                \n",
    "            elif values=='PAD' or values == 'BOH' or values == \"BOS\" or values == 'BOV' or  values=='EOV' or values=='EOH':\n",
    "                found = 1\n",
    "                codeType[keys] = 'T'\n",
    "                countT= countT+1\n",
    "            else:\n",
    "                for k,v in ICD_9_10_to_CSS.items():\n",
    "                    if values in v:\n",
    "                        found = 1\n",
    "                        if keys not in codeType:\n",
    "                            if k.startswith('D'):\n",
    "                                codeType[keys] = 'D'\n",
    "                                countD = countD+1\n",
    "                            elif k.startswith('P'):\n",
    "                                codeType[keys] = 'P'\n",
    "                                countP = countP+1\n",
    "            if found == 0:\n",
    "                print(keys,values)\n",
    "    print(countD,countP,countDr,countT)        \n",
    "    pickle.dump(codeType, open(outFile+'.codeType', 'wb'), -1)\n",
    "    \n",
    "    return codeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61e1ac9f-aa3d-4f88-af4d-1fed4ea9ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(outFile):\n",
    "    # load the data again\n",
    "    seqs = pickle.load(open(outFile +'.seqs','rb'))\n",
    "    types = pickle.load(open(outFile + '.types','rb'))\n",
    "    codeType = pickle.load(open(outFile + '.codeType','rb'))\n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "    return seqs,types,codeType,reverseTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad80bd71-420f-49e7-bd39-a71115e61ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForTF(sequence):\n",
    "    X, y, pairs = list(), list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        if i+1 >= len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[:i+1], sequence[i+1:]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    pairs=pairing1(X,y)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa1a9c6d-db94-4a1c-b0d1-a3f6a8f57860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForSDP(sequence):\n",
    "    X, y,pairs = list(), list(),list()\n",
    "    for i in range(len(sequence)):\n",
    "    # find the end of this pattern\n",
    "        #print(f\"i:{i}, seq: {len(sequence)} \\n {sequence}\")\n",
    "        # check if we are beyond the sequence\n",
    "        if i+1 >= len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[:i+1], [sequence[i+1]]\n",
    "        #print(f\"X: {seq_x} ----\\n Y: {seq_y}\")\n",
    "       # print(\"in\")\n",
    "        #print(sequence[:i+1],sequence[i+1])\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        #print(f\"X: {X}, Y: {y}\")\n",
    "    pairs=pairing1(X,y)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1463be0d-29fd-4de8-b4ab-845837a105dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForSDPclean(sequence):\n",
    "    X, y,pairs = list(), list(),list()\n",
    "    for i in range(len(sequence)-1):\n",
    "\n",
    "        #seq_x, seq_y = sequence[:i+1], [sequence[i+1]]\n",
    "        X.append(sequence[:i+1])\n",
    "        y.append( [sequence[i+1]])\n",
    "        #print(f\"X: {X}, Y: {y}\")\n",
    "    pairs=pairing1(X,y)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fd1ca0d-b605-4335-b19d-7c18b9d4f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForDAI(sequence, n_steps):\n",
    "    X,pairs = list(),list()\n",
    "    for i in range(n_steps):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input  parts of the pattern\n",
    "        seq_x = sequence[i:]\n",
    "        X.append(seq_x)\n",
    "    pairs=pairing2(X)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae4f8d20-4431-4c4d-8254-d9064b34bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePairs(newPairs, mn = 600):\n",
    "    print(f\"\\n  Total no of pairs before removing :{len(newPairs)}\")\n",
    "    b = len(newPairs)\n",
    "    x,y,curPair = [],[],[]\n",
    "    count,county,counts =0,0,0\n",
    "    for pair in newPairs:\n",
    "        if len(pair[0]) > mn and len(pair[1]) > mn:\n",
    "            counts =counts +1\n",
    "            #newPairs.remove(pair)   \n",
    "        elif len(pair[0]) > mn or len(pair[1]) > mn:\n",
    "            count =count +1\n",
    "            #newPairs.remove(pair)\n",
    "        else:\n",
    "            curPair.append(pair)\n",
    "            \n",
    "    print(f\"\\n  Total no of pairs after removing :{len(curPair)}\")\n",
    "    print(f\"\\n  Total no of pairs removed :{b-len(curPair)}\")\n",
    "    return curPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "106ca9ca-f979-472a-93d0-f9dc7e14acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(originalSeqs, dataFormat = 'TF', mn = 400):\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(len(originalSeqs)):\n",
    "        # Trajectory forecasting (TF): predict until the end of EOH\n",
    "        if dataFormat == 'TF':\n",
    "            pairs.extend(PrepareForTF(originalSeqs[i]))\n",
    "        # Sequential disease prediction (SDP): predict until the next visit\n",
    "        elif dataFormat == 'SDP':\n",
    "            pairs.extend(PrepareForSDP(originalSeqs[i]))\n",
    "        elif dataFormat == 'DAI':\n",
    "            pairs.extend(PrepareForDAI(originalSeqs[i],1))\n",
    "        else:\n",
    "            \n",
    "            print(\"Wrong Format\")\n",
    "            \n",
    "    newPairs,p = [], []\n",
    "\n",
    "    for pair in pairs:\n",
    "        #print(\"paiot\",pair)\n",
    "        input,output,p =[],[],[]\n",
    "        for i in pair[0]:\n",
    "            #print(\"i\",i)\n",
    "            i = i +[2]\n",
    "            input.extend(i)\n",
    "        p.append([1]+ input + [3])\n",
    "        for o in pair[1]:\n",
    "            o = o +[2]\n",
    "            #print(\"o\",o)\n",
    "            output.extend(o)\n",
    "        p.append([1]+ output+ [3])\n",
    "\n",
    "        newPairs.append(tuple(p))\n",
    "    ## sample\n",
    "    n =2\n",
    "    #print(f\" Orginal: {pairs[:10]}  \\n\\n\\n After formating : {newPairs[:10]} \\n ----------------------------------------\\n\\n\\n\")\n",
    "    if(stats(newPairs, mn = mn)):\n",
    "        print(f\"\\n\\n\\nRemoving pairs greater than  {mn} seq length\")\n",
    "        newPairs = removePairs(newPairs,mn=mn)\n",
    "        stats(newPairs)\n",
    "    return newPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "862bb4d2-59f7-4ecc-ac6b-61241e886e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing1(x,y):\n",
    "    pairs =[]\n",
    "    for i,a in enumerate(zip(x,y)):\n",
    "        pairs.append(a)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04d83f75-a1f1-4938-baf5-909a51b89346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing2(x):\n",
    "    inp,trg,pairs =[],[],[]\n",
    "    for x in x:\n",
    "        inp.append(x[:-1])\n",
    "        trg.append(x[1:])\n",
    "    for i,a in enumerate(zip(inp,trg)):\n",
    "        pairs.append(a)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bab2c052-37ec-4516-a2ab-9387d1bca780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing3(x):\n",
    "    inp,trg,pairs =[],[],[]\n",
    "    for x in x:\n",
    "        inp.append(x[:-1])\n",
    "        trg.append([x[-1]])\n",
    "    for i,a in enumerate(zip(inp,trg)):\n",
    "        pairs.append(a)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4ec046d-5f82-49e4-babd-216e3ca42bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(newPairs,mn =600):\n",
    "    x,y = [],[]\n",
    "    count,county,counts =0,0,0\n",
    "    for pair in newPairs:\n",
    "        if len(pair[0]) > mn:\n",
    "            count =count +1\n",
    "\n",
    "        if len(pair[1]) > mn:\n",
    "            county =county +1 \n",
    "\n",
    "        if len(pair[0])>mn and len(pair[1])  >mn:\n",
    "            counts = counts +1\n",
    "        x.append(len(pair[0]))\n",
    "        y.append(len(pair[1]))\n",
    "    #print(f\"\\n Statistics of the input and output data\")\n",
    "    #print(f\"\\n Avg seq len y: {sum(y)/len(y)} ,  Avg seq len x: {sum(x)/len(x)}\")  \n",
    "    #print(f\"\\n Total no of pairs > seq of len({mn}): \\n X: {count},\\n Y : {county},\\n X,Y : {counts},\\n total pairs :{len(newPairs)} \\n max value X :{max(torch.tensor(x)) }\\n max value Y :{max(torch.tensor(y))}\")\n",
    "    if count > 0 or county > 0 or counts > 0:\n",
    "        run = True\n",
    "    else:\n",
    "        run = False\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bfadec4-9355-4ade-9524-e0cc1ef04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetIntegerOutput(updSeqs,isall =1):\n",
    "    # updating the output codes to reduce hypothesis space as some of the medical codes have been removed.\n",
    "\n",
    "    # outTypes = {prev-codes : new-codes} ,  token codes remain same \n",
    "    updPair = []\n",
    "    outTypes = {}\n",
    "    outTypes.update({0:0 , 1:1,  2:2, 3:3})\n",
    "    for i,pair in enumerate(updSeqs):\n",
    "        newVisit = []\n",
    "        for code in pair[1]:\n",
    "            if code in outTypes:\n",
    "                newVisit.append(outTypes[code])\n",
    "            else:\n",
    "                outTypes[code] = len(outTypes)\n",
    "                newVisit.append(outTypes[code])\n",
    "        updPair.append((pair[0],newVisit))\n",
    "    return updPair,outTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c552d0-2bf8-48ae-8bf4-43bc402819f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateOutput(newPairs, codeType, diagnosis=0, procedure=0, drugs =0, all = 0):\n",
    "    updSeqs = []\n",
    "    if procedure == 1 and drugs == 1:\n",
    "        print(\"\\n Removing drug and procedure codes from output for forecasting diagnosis code only\")\n",
    "        for i,pair in enumerate(newPairs):\n",
    "            newOutput = []\n",
    "            for code in pair[1]:\n",
    "                if (codeType[code] =='D' or codeType[code] =='T'):\n",
    "                    newOutput.append(code)\n",
    "                        \n",
    "            if len(newOutput) >= 4:\n",
    "            #print(f\"{newOutput} \\n\")\n",
    "                updSeqs.append((pair[0],newOutput))\n",
    "    if drugs == 1 and procedure == 0:\n",
    "        print(\"\\n Removing only drug codes from output for forecasting diagnosis and procedure code only\")\n",
    "        for i,pair in enumerate(newPairs):\n",
    "            newOutput = []\n",
    "            for code in pair[1]:\n",
    "                if not (codeType[code] == 'DR'):\n",
    "                    newOutput.append(code)\n",
    "            if len(newOutput)>=4:\n",
    "                updSeqs.append((pair[0],newOutput))\n",
    "    if all:\n",
    "        print(\"\\n keeping all codes\")\n",
    "        updSeqs = newPairs.copy()\n",
    "        \n",
    "    return updSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d282296-f466-446f-af21-5df54eac48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeFiles(pair,outTypes,codeType,types,reverseTypes,outFile):\n",
    "    if not os.path.exists(outFile):\n",
    "        os.makedirs(outFile)\n",
    "    pickle.dump(pair, open(outFile+'.seqs', 'wb'), -1)\n",
    "    pickle.dump(outTypes, open(outFile+'.outTypes', 'wb'), -1)\n",
    "    pickle.dump(codeType, open(outFile+'.codeType', 'wb'), -1)\n",
    "    pickle.dump(types, open(outFile+'.types', 'wb'), -1)\n",
    "    pickle.dump(reverseTypes, open(outFile+'.reverseTypes', 'wb'), -1)\n",
    "    reverseOutTypes = {v:k for k,v in outTypes.items()}\n",
    "    pickle.dump(reverseOutTypes, open(outFile+'.reverseTypes', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dab48b6-1a49-4c4b-958e-ca9999421eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCS_DIR = './CSS/'\n",
    "\n",
    "CCSRDX_file = os.path.join(CCS_DIR, 'DXCCSR_v2021-2.csv')\n",
    "CCSRPCS_file = os.path.join(CCS_DIR, 'PRCCSR_v2021-1.CSV')\n",
    "\n",
    "CCSDX_file = os.path.join(CCS_DIR, '$dxref 2015.csv')\n",
    "CCSPX_file = os.path.join(CCS_DIR, '$prref 2015.csv')\n",
    "\n",
    "D_CCSR_Ref_file = os.path.join(CCS_DIR, 'DXCCSR-Reference-File-v2021-2.xlsx')\n",
    "P_CCSR_Ref_file = os.path.join(CCS_DIR, 'PRCCSR-Reference-File-v2021-1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd0ddd50-c233-4d21-a371-d508b880fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Building subject_id-admission mapping, admission-date mapping\n",
      "Building admission-diagnosis mapping\n",
      "-Number of null ICD9 codes in file mimic-iv-2.2/hosp/diagnoses_icd.csv.gz: 0\n",
      "-Number of null ICD10 codes in file mimic-iv-2.2/hosp/diagnoses_icd.csv.gz: 0\n",
      "Building admission-procedure mapping\n",
      "-Number of null ICD9 codes in file mimic-iv-2.2/hosp/procedures_icd.csv.gz: 0\n",
      "-Number of null ICD10 codes in file mimic-iv-2.2/hosp/procedures_icd.csv.gz: 0\n",
      "Building admission-drug mapping\n",
      "\n",
      " Completed...\n",
      "\n",
      " Cleaning data...\n",
      "Cleaning data...\n",
      "Removing patient records who does not have all three medical codes for an admission\n",
      "Removing patient who made less than 2 admissions\n",
      " Total Number of patients 19834\n",
      " Total Number of admissions 52957\n",
      " Average number of admissions per patient 2.6700110920641325\n",
      " Total Number of diagnosis code 14119\n",
      " Total Number of procedure code 7511\n",
      " Total Number of drug code 4891\n",
      " Total Number of codes 26521\n",
      " average Number of procedure code per visit 3.081991049341919\n",
      " average Number of diagnosis code per visit 11.927412806616688\n",
      " average Number of Drug code per visit 50.46753026039995\n",
      "\n",
      " Completed...\n",
      "\n",
      "Mapping ICD data to CCS and CCSR...\n",
      "Total ICD to ccs entries: 144424\n",
      "Total ccs codes/descriptions: 514\n",
      "total number of unqiue codes(DIag + proc): 828\n",
      "total number of ICD9 codes used 0 and ICD10 codes: 0\n",
      "-Total number (complete set) of ICD9+ICD10 codes (diag + proc): 144424\n",
      "-Total number of ICD codes actually used: 14112\n",
      "-Total number of ICD codes missing in the admissions list:  7\n",
      "here it should be working\n",
      "['P10_0QS604Z']\n",
      "---------------\n",
      "total number of ICD9 codes used 0 and ICD10 codes: 0\n",
      "-Total number (complete set) of ICD9+ICD10 codes (diag + proc): 144424\n",
      "-Total number of ICD codes actually used: 5773\n",
      "-Total number of ICD codes missing in the admissions list:  8170\n",
      "True\n",
      " Total Number of diagnosis code 754\n",
      " Total Number of procedure code 466\n",
      " Total Number of drug code 4891\n",
      " Total Number of unique  D,P codes 1220\n",
      " Total Number of all codes 6111\n",
      " average Number of procedure code per visit 3.0384502322299958\n",
      " average Number of diagnosis code per visit 12.549105878354137\n",
      " average Number of drug code per visit 50.46753026039995\n",
      " Min. and max. Number of diagnosis code per admission (1, 56)\n",
      " Min. and max. Number of procedure code  per admission(1, 41)\n",
      " Min. and max. Number of drug code  per admission (1, 1202)\n",
      "\n",
      " Completed...\n",
      "\n",
      " Trimming the codes assigned per visit based on a threshold...\n",
      "Trimming the diagnosis, procedure, and medication codes for each visit\n",
      " Total Number of diagnosis code 754\n",
      " Total Number of procedure code 466\n",
      " Total Number of drug code 4787\n",
      " Total Number of unique  D,P codes 1220\n",
      " Total Number of all codes 6007\n",
      " average Number of procedure code per visit 3.0384502322299958\n",
      " average Number of diagnosis code per visit 12.549105878354137\n",
      " average Number of drug code per visit 38.60158241592235\n",
      " Min. and max. Number of diagnosis code per admission (1, 56)\n",
      " Min. and max. Number of procedure code  per admission(1, 41)\n",
      " Min. and max. Number of drug code  per admission (1, 80)\n",
      "\n",
      " Completed...\n",
      "\n",
      " Building the data..\n",
      "Building admission-Visits mapping & filtering patients with less than 2 \n",
      "0 subjects were removed\n",
      "Building subject-id, diagnosis,procedure,drugs mapping\n",
      "Converting Strings Codes into unique integer, and making types\n",
      "\n",
      " removing the code whose occurence is less than a certain threshold: 5\n",
      "2.6700110920641325\n",
      " Total number of codes removed: 1521  \n",
      " Total number of  unique codes : 6007  \n",
      "\n",
      " Save the data before formmating based on the task\n",
      "691 424 3371 6\n",
      "\n",
      " Completed...\n",
      "\n",
      " Preparing data for Trajectory Forecasting....\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32571\n",
      "\n",
      "  Total no of pairs removed :552\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32571\n",
      "\n",
      "  Total no of pairs removed :552\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " Removing only drug codes from output for forecasting diagnosis and procedure code only\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " Removing only drug codes from output for forecasting diagnosis and procedure code only\n",
      "\n",
      " total # S1 records : 32570\n",
      " total # S2 records :32571\n",
      " total # S3 records :32571\n",
      "\n",
      " total Dx codes:695 \n",
      "  total Dx,Px codes:1119 \n",
      " total Dx,Px,Rx codes:4490\n",
      "\n",
      " Storing all the information related to Trajectory Forecasting...\n",
      "\n",
      " Completed...\n",
      "\n",
      "Preparing data for Sequential disease prediction....\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32808\n",
      "\n",
      "  Total no of pairs removed :315\n",
      "\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " total # records: 32807 \n",
      " total # of codes: 695\n",
      "\n",
      " Storing all the information related to TSequential disease prediction...\n",
      "\n",
      " Completed...\n",
      "\n",
      " All the preprocessing step has been completed, Now use the data in the outputData folder to build the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the data...\")\n",
    "subject_idAdmMap,admDxMap,admPxMap,admDrugMap,drugDescription = load_mimic_data()\n",
    "print(\"\\n Completed...\")\n",
    "#stage 2 and 3\n",
    "print(\"\\n Cleaning data...\")\n",
    "subject_idAdmMap,adDx,adPx,adDrug = clean_data(subject_idAdmMap,admDxMap,admPxMap,admDrugMap)\n",
    "print(\"\\n Completed...\")\n",
    "#stage 4\n",
    "print(\"\\nMapping ICD data to CCS and CCSR...\")\n",
    "adDx,adPx,codeDescription = icd_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file,D_CCSR_Ref_file,P_CCSR_Ref_file,adDx,adPx,adDrug,drugDescription)\n",
    "print(\"\\n Completed...\")\n",
    "#stage 5\n",
    "print(\"\\n Trimming the codes assigned per visit based on a threshold...\")\n",
    "min_dx, min_px, min_drg = 80, 80, 80 \n",
    "adDx, adPx, adDrug= trim(adDx, adPx, adDrug, min_dx, min_px, min_drg)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n Building the data..\")\n",
    "newSeqs,types=buildData(subject_idAdmMap,adDx,adPx,adDrug)\n",
    "#stage 6\n",
    "threshold = 5\n",
    "print(f\"\\n removing the code whose occurence is less than a certain threshold: {threshold}\")\n",
    "updatedSeqs ,types ,reverseTypes  = removeCode(newSeqs,types,threshold=threshold)\n",
    "# outFile - is a folder path in the working directory where the data is going to get stored\n",
    "outFile = os.path.join('outputData','originalData')\n",
    "print(\"\\n Save the data before formmating based on the task\")\n",
    "saveFiles(updatedSeqs,dict(types),codeDescription)\n",
    "codeType = generateCodeTypes(outFile,reverseTypes)\n",
    "seqs,types,codeType,reverseTypes = load_data(outFile)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n Preparing data for Trajectory Forecasting....\")\n",
    "# sequence length threshold  -mn\n",
    "seqLength = 500\n",
    "newPairs = formatData(seqs,dataFormat = 'TF', mn = seqLength)\n",
    "diagnosisOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d')\n",
    "diagnosisProcedureOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p')\n",
    "AllOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p_dr')\n",
    "# sequence length threshold  -mn\n",
    "seqLength = 500\n",
    "newPairs = formatData(seqs,dataFormat = 'TF', mn = seqLength)\n",
    "diagnosisOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d')\n",
    "diagnosisProcedureOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p')\n",
    "AllOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p_dr')\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "print(f\"\\n Remove certain codes from output for different data formats\")\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "diagnosisProcedureUpdPair,diagnosisProcedureOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =1,all =0))\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "print(f\"\\n Remove certain codes from output for different data formats\")\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "diagnosisProcedureUpdPair,diagnosisProcedureOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =1,all =0))\n",
    "\n",
    "print(f\"\\n total # S1 records : {len(diagnosisUpdPair)}\\n total # S2 records :{len(diagnosisProcedureUpdPair)}\\n total # S3 records :{len(AllUpdPair)}\")\n",
    "print(f\"\\n total Dx codes:{len(diagnosisOutTypes)} \\n  total Dx,Px codes:{len(diagnosisProcedureOutTypes)} \\n total Dx,Px,Rx codes:{len(AllOutTypes)}\")\n",
    "print(\"\\n Storing all the information related to Trajectory Forecasting...\")\n",
    "\n",
    "\n",
    "storeFiles(diagnosisUpdPair,diagnosisOutTypes,codeType,types,reverseTypes,diagnosisOutputFile)\n",
    "storeFiles(diagnosisProcedureUpdPair,diagnosisProcedureOutTypes,codeType,types,reverseTypes,diagnosisProcedureOutputFile)\n",
    "storeFiles(AllUpdPair,AllOutTypes,codeType,types,reverseTypes,AllOutputFile)\n",
    "print(\"\\n Completed...\")\n",
    "\n",
    "print(\"\\nPreparing data for Sequential disease prediction....\")\n",
    "newPairs = formatData(seqs,dataFormat = 'SDP',mn =500)\n",
    "diagnosisOutputFile = os.path.join('outputData','SDP','Inp_d_p_dr_out_d')\n",
    "\n",
    "print(f\"\\n\\n Remove certain codes from output for different data formats\")\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "\n",
    "print(f\"\\n total # records: {len(diagnosisUpdPair)} \\n total # of codes: {len(diagnosisOutTypes)}\")\n",
    "\n",
    "print(\"\\n Storing all the information related to TSequential disease prediction...\")\n",
    "storeFiles(diagnosisUpdPair,diagnosisOutTypes,codeType,types,reverseTypes,diagnosisOutputFile)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n All the preprocessing step has been completed, Now use the data in the outputData folder to build the model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c47e5-9afc-47e1-bd4d-7e9e8c122754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
