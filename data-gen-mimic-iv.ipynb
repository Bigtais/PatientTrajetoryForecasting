{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1aa5f799-237c-4e5b-9d14-77f82fc98378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebooks is an attempt to port the code form https://github.com/MostHumble/Clinical-GAN/blob/master/process_data.py \n",
    "# to a more recent mimic dataset version\n",
    "# while adding suitable updates that weren't taken into account: for now mailnly scheduled to work on stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6abc67-8c82-4935-8f76-ec08b074a85a",
   "metadata": {},
   "source": [
    "# Done porting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad943fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "import gzip\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "#parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a1c23b-86ee-4843-872d-f0af867ab682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions.csv.gz\t emar_detail.csv.gz\t    poe_detail.csv.gz\n",
      "d_hcpcs.csv.gz\t\t hcpcsevents.csv.gz\t    prescriptions.csv.gz\n",
      "diagnoses_icd.csv.gz\t labevents.csv.gz\t    procedures_icd.csv.gz\n",
      "d_icd_diagnoses.csv.gz\t microbiologyevents.csv.gz  provider.csv.gz\n",
      "d_icd_procedures.csv.gz  omr.csv.gz\t\t    services.csv.gz\n",
      "d_labitems.csv.gz\t patients.csv.gz\t    transfers.csv.gz\n",
      "drgcodes.csv.gz\t\t pharmacy.csv.gz\n",
      "emar.csv.gz\t\t poe.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls mimic-iv-2.2/hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b43c66-facc-4071-87e3-d6fde9f2cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_path = 'mimic-iv-2.2/hosp'\n",
    "CCSRDX_file = 'DXCCSR_v2021-2/DXCCSR_v2021-2.csv'\n",
    "CCSRPCS_file = 'PRCCSR_v2021-1/PRCCSR_v2021-1.csv'\n",
    "admissionFile = os.path.join(mimic_iv_path, 'admissions.csv.gz')\n",
    "diagnosisFile = os.path.join(mimic_iv_path, 'diagnoses_icd.csv.gz')\n",
    "procedureFile = os.path.join(mimic_iv_path, 'procedures_icd.csv.gz')\n",
    "prescriptionFile = os.path.join(mimic_iv_path, 'prescriptions.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d21e802-6b27-4756-a628-8809fae1c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = pd.read_csv(admissionFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d99f82-8c2f-48a4-b6d4-c01196f810ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admit_provider_id</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>P874LG</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Other</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-05-06 19:17:00</td>\n",
       "      <td>2180-05-06 23:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-26 18:27:00</td>\n",
       "      <td>2180-06-27 18:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P09Q6Y</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>2180-06-26 21:31:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P60CC5</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOSPICE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>2180-08-06 01:44:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P30KEH</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-07-23 05:54:00</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000068</td>\n",
       "      <td>25022803</td>\n",
       "      <td>2160-03-03 23:16:00</td>\n",
       "      <td>2160-03-04 06:26:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EU OBSERVATION</td>\n",
       "      <td>P51VDL</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2160-03-03 21:55:00</td>\n",
       "      <td>2160-03-04 06:26:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            admittime            dischtime deathtime  \\\n",
       "0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00       NaN   \n",
       "1    10000032  22841357  2180-06-26 18:27:00  2180-06-27 18:49:00       NaN   \n",
       "2    10000032  25742920  2180-08-05 23:44:00  2180-08-07 17:50:00       NaN   \n",
       "3    10000032  29079034  2180-07-23 12:35:00  2180-07-25 17:55:00       NaN   \n",
       "4    10000068  25022803  2160-03-03 23:16:00  2160-03-04 06:26:00       NaN   \n",
       "\n",
       "   admission_type admit_provider_id      admission_location  \\\n",
       "0          URGENT            P874LG  TRANSFER FROM HOSPITAL   \n",
       "1        EW EMER.            P09Q6Y          EMERGENCY ROOM   \n",
       "2        EW EMER.            P60CC5          EMERGENCY ROOM   \n",
       "3        EW EMER.            P30KEH          EMERGENCY ROOM   \n",
       "4  EU OBSERVATION            P51VDL          EMERGENCY ROOM   \n",
       "\n",
       "  discharge_location insurance language marital_status   race  \\\n",
       "0               HOME     Other  ENGLISH        WIDOWED  WHITE   \n",
       "1               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "2            HOSPICE  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "3               HOME  Medicaid  ENGLISH        WIDOWED  WHITE   \n",
       "4                NaN     Other  ENGLISH         SINGLE  WHITE   \n",
       "\n",
       "             edregtime            edouttime  hospital_expire_flag  \n",
       "0  2180-05-06 19:17:00  2180-05-06 23:30:00                     0  \n",
       "1  2180-06-26 15:54:00  2180-06-26 21:31:00                     0  \n",
       "2  2180-08-05 20:58:00  2180-08-06 01:44:00                     0  \n",
       "3  2180-07-23 05:54:00  2180-07-23 14:00:00                     0  \n",
       "4  2160-03-03 21:55:00  2160-03-04 06:26:00                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619231a0-7d44-4524-9891-48a2fdb1aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_icd(code: str, version: int, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Reformat the given ICD code based on the specified version.\n",
    "\n",
    "    Args:\n",
    "        code (str): The ICD code to be reformatted.\n",
    "        version (int): The version of the ICD code (9 or 10).\n",
    "        is_diag (bool): Indicates whether the code is a diagnosis code or not.\n",
    "\n",
    "    Returns:\n",
    "        str: The reformatted ICD code.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the version is neither 9 nor 10.\n",
    "    \"\"\"\n",
    "    if version == 9:\n",
    "        return reformat_icd9(code, is_diag)\n",
    "    elif version == 10:\n",
    "        return reformat_icd10(code, is_diag)\n",
    "    else:\n",
    "        raise ValueError(\"version must be 9 or 10\")\n",
    "\n",
    "def reformat_icd10(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Reformat the given ICD-10 code.\n",
    "\n",
    "    Args:\n",
    "    code (str): The ICD-10 code to be reformatted.\n",
    "    is_diag (bool): Indicates whether the code is a diagnosis code or not.\n",
    "\n",
    "    Returns:\n",
    "    str: The reformatted ICD-10 code.\n",
    "\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if not is_diag:\n",
    "        return code\n",
    "    return code[:3] + \".\" + code[3:]\n",
    "\n",
    "\n",
    "def reformat_icd9(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Reformat the given ICD-9 code based on the provided parameters putting a point in the right place.\n",
    "\n",
    "    Args:\n",
    "        code (str): The ICD-9 code to be reformatted.\n",
    "        is_diag (bool): A flag indicating whether the code is a diagnosis code or not.\n",
    "\n",
    "    Returns:\n",
    "        str: The reformatted ICD-9 code.\n",
    "\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if is_diag:\n",
    "        if code.startswith(\"E\"):\n",
    "            if len(code) > 4:\n",
    "                return code[:4] + \".\" + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                return code[:3] + \".\" + code[3:]\n",
    "    else:\n",
    "        if len(code) > 2:\n",
    "            return code[:2] + \".\" + code[2:]\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b553c9-23bd-4a80-bd28-ea23ff7fb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ICDs_from_mimic_file(fileName: str, isdiagnosis: bool = True) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    Retrieves ICD codes from a MIMIC file.\n",
    "\n",
    "    Args:\n",
    "        fileName (str): The path to the MIMIC file.\n",
    "        isdiagnosis (bool, optional): Specifies whether to retrieve diagnosis codes (True) or procedure codes (False). \n",
    "                                      Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping hospital admission IDs (hadm_id) to a list of corresponding ICD codes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mapping = {}\n",
    "    mimicFile = gzip.open(fileName, 'r')\n",
    "        \n",
    "    codes = []\n",
    "    \n",
    "    number_of_null_ICD9_codes = 0\n",
    "    number_of_null_ICD10_codes = 0\n",
    "    mimicFile.readline()\n",
    "    for line in mimicFile:  #   0  ,     1    ,    2   ,   3  ,    4\n",
    "        tokens = line.decode('utf-8').strip().split(',')\n",
    "        #print(tokens)\n",
    "        hadm_id = int(tokens[1])\n",
    "        # depending on the file, the ICD code is in different columns (3 for diagnosis, 4 for procedures)\n",
    "        if (isdiagnosis and len(tokens[3]) == 0) or (not isdiagnosis and len(tokens[4]) == 0):\n",
    "            if isdiagnosis:\n",
    "                if (tokens[4] =='9'):\n",
    "                    # ignore diagnoses where ICD9_code is null\n",
    "                    number_of_null_ICD9_codes += 1\n",
    "                else:\n",
    "                    number_of_null_ICD10_codes += 1\n",
    "                continue\n",
    "            else:\n",
    "                if (tokens[5] =='9'):\n",
    "                    # ignore diagnoses where ICD9_code is null\n",
    "                    number_of_null_ICD9_codes += 1\n",
    "                else:\n",
    "                    number_of_null_ICD10_codes += 1\n",
    "                continue\n",
    "                \n",
    "        if isdiagnosis:\n",
    "            ICD_code = tokens[3]\n",
    "        else:\n",
    "            ICD_code = tokens[4] \n",
    "\n",
    "        if ICD_code.find(\"\\\"\") != -1:\n",
    "            ICD_code = ICD_code[1:-1].strip()  # toss off quotes and proceed\n",
    "\n",
    "        # since diagnosis and procedure ICD9 codes have intersections, a prefix is necessary for disambiguation\n",
    "        if isdiagnosis:\n",
    "            ICD_code = 'D' + tokens[4]+ '_' +ICD_code\n",
    "        else:\n",
    "            ICD_code = 'P' + tokens[5] + '_' + ICD_code\n",
    "\n",
    "        if hadm_id in mapping:\n",
    "            mapping[hadm_id].append(ICD_code.strip())\n",
    "        else:\n",
    "            mapping[hadm_id]= [ICD_code.strip()]  \n",
    "\n",
    "    mimicFile.close()\n",
    "    print ('-Number of null ICD9 codes in file ' + fileName + ': ' + str(number_of_null_ICD9_codes))\n",
    "    print ('-Number of null ICD10 codes in file ' + fileName + ': ' + str(number_of_null_ICD10_codes))\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9342d066-8192-4a4b-a783-9972c30b3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drugs_from_mimic_file(fileName :str, choice : Optional[str] ='ndc') -> Tuple[Dict[str, str], Dict[int, list]]:\n",
    "    \"\"\"\n",
    "    Extracts drug information from a MIMIC file.\n",
    "\n",
    "    Args:\n",
    "        fileName (str): The path to the MIMIC file.\n",
    "        choice (str, optional): The choice of drug code to extract. Defaults to 'ndc'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries:\n",
    "            - drugDescription: A dictionary mapping drug codes to their descriptions.\n",
    "            - mapping: A dictionary mapping hospital admission IDs to lists of drug codes.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If an error occurs while processing the MIMIC file.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    drugDescription = {}\n",
    "    mimicFile = gzip.open(fileName, 'r')  # subject_id,hadm_id,gsn,ndc,drug\n",
    "    mimicFile.readline()\n",
    "    number_of_null_NDC_codes = 0\n",
    "    try:\n",
    "        for line in mimicFile:\n",
    "            tokens = line.decode('utf-8').strip().split(',')\n",
    "            hadm_id = int(tokens[1])\n",
    "            if choice =='ndc':\n",
    "                drug_code = tokens[12]\n",
    "            else:\n",
    "                drug_code = tokens[11]\n",
    "            drug_code = drug_code.strip()\n",
    "            drug_code = 'DR'+'_'+drug_code\n",
    "            if hadm_id in mapping:\n",
    "                mapping[hadm_id].append(drug_code.strip())\n",
    "            else:\n",
    "                mapping[hadm_id]=[drug_code.strip()]\n",
    "            if drug_code not in drugDescription:\n",
    "                drugDescription[drug_code] = tokens[9]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    mimicFile.close()\n",
    "    return drugDescription, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6ba2f3-d66b-4a5e-ab29-45b03844d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mimic_data(choice : Optional[str] = 'ndc'):\n",
    "    \"\"\"\n",
    "    Loads MIMIC data and returns various mappings.\n",
    "\n",
    "    Args:\n",
    "    - choice (Optional[str]): The choice of drug mapping. Defaults to 'ndc'.\n",
    "\n",
    "    Returns:\n",
    "    - subject_idAdmMap (dict): A dictionary mapping subject_id to a list of admission IDs.\n",
    "    - admDxMap (dict): A dictionary mapping admission IDs to diagnosis codes.\n",
    "    - admPxMap (dict): A dictionary mapping admission IDs to procedure codes.\n",
    "    - admDrugMap (dict): A dictionary mapping admission IDs to drug codes.\n",
    "    - drugDescription (dict): A dictionary mapping drug codes to drug descriptions.\n",
    "    \"\"\"\n",
    "    print ('Building subject_id-admission mapping, admission-date mapping')\n",
    "    previous_subject = 0\n",
    "    previous_admission = 0\n",
    "    subject_idAdmMap = {}\n",
    "    admDateMap = {}\n",
    "    subject_idStatic = {}   # adm type, Insurance , ethnicity , marital status\n",
    "    infd = gzip.open(admissionFile, 'r')\n",
    "    infd.readline()\n",
    "    for line in infd:\n",
    "        tokens = line.decode('utf-8').strip().split(',')\n",
    "        subject_id = int(tokens[0])\n",
    "        hadm_id = int(tokens[1])\n",
    "        if subject_id in subject_idAdmMap: \n",
    "            subject_idAdmMap[subject_id].add(hadm_id)\n",
    "        else: \n",
    "            subject_idAdmMap[subject_id] = set()\n",
    "            subject_idAdmMap[subject_id].add(hadm_id)\n",
    "    for subject_id in subject_idAdmMap.keys():\n",
    "        subject_idAdmMap[subject_id] = list(subject_idAdmMap[subject_id])  \n",
    "    infd.close()\n",
    "\n",
    "    print ('Building admission-diagnosis mapping')\n",
    "    admDxMap = get_ICDs_from_mimic_file(diagnosisFile)\n",
    "\n",
    "    print ('Building admission-procedure mapping')\n",
    "    admPxMap = get_ICDs_from_mimic_file(procedureFile, isdiagnosis=False)\n",
    "\n",
    "    print ('Building admission-drug mapping')\n",
    "    drugDescription, admDrugMap = get_drugs_from_mimic_file(prescriptionFile, choice)\n",
    "    return subject_idAdmMap,admDxMap,admPxMap,admDrugMap,drugDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e13c57-1f8a-484d-a690-70288bfc7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateAdmCodeList(subject_idAdmMap: Dict[int, List[int]], admDxMap:  Dict[int, List[str]], admPxMap : Dict[int, List[str]], admDrugMap :  Dict[int, List[str]]) -> Tuple[Dict[int, List[str]], Dict[int, List[str]], Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Update the admission code lists for each admission ID (to take into account deleted elements).\n",
    "\n",
    "    Args:\n",
    "        subject_idAdmMap (dict): A dictionary mapping subject IDs to a list of admission IDs.\n",
    "        admDxMap (dict): A dictionary mapping admission IDs to diagnosis codes.\n",
    "        admPxMap (dict): A dictionary mapping admission IDs to procedure codes.\n",
    "        admDrugMap (dict): A dictionary mapping admission IDs to drug codes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three dictionaries:\n",
    "            - adDx: A dictionary mapping admission IDs to diagnosis codes.\n",
    "            - adPx: A dictionary mapping admission IDs to procedure codes.\n",
    "            - adDrug: A dictionary mapping admission IDs to drug codes.\n",
    "    \"\"\"\n",
    "    adDx = {}\n",
    "    adPx = {}\n",
    "    adDrug = {}\n",
    "    for subject_id, admIdList in subject_idAdmMap.items():\n",
    "        for admId in admIdList:\n",
    "            adDx[admId] = admDxMap[admId]\n",
    "            adPx[admId] = admPxMap[admId]\n",
    "            adDrug[admId] = admDrugMap[admId]\n",
    "            \n",
    "    return adDx, adPx, adDrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f949ce20-8d88-413d-9c43-f00fec6446b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListAvgVisit(dic: Dict[int, List[int]]) -> float:\n",
    "    a =[len(intList) for k,intList in dic.items()]\n",
    "    return sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f32fe91c-011f-4e64-acdd-4595ac616480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "def countCodes(*dicts: Dict[int, List[str]]) -> int:\n",
    "    all_values = [value for dic in dicts for value in dic.values()]\n",
    "    code_counts = Counter(code for sublist in all_values for code in sublist)\n",
    "    return len(code_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f2d20a-47b4-439f-ac01-141a8be23eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(pidAdmMap,admDxMap,admPxMap,admDrugMap):\n",
    "    print(f\" Total Number of patients {len(pidAdmMap)}\")\n",
    "    print(f\" Total Number of admissions {len(admDxMap)}\")\n",
    "    print(f\" Average number of admissions per patient {ListAvgVisit(pidAdmMap)}\")\n",
    "    print(f\" Total Number of diagnosis code {countCodes(admDxMap)}\")\n",
    "    print(f\" Total Number of procedure code {countCodes(admPxMap)}\")\n",
    "    print(f\" Total Number of drug code {countCodes(admDrugMap)}\")\n",
    "    print(f\" Total Number of codes {countCodes(admPxMap) +countCodes(admDxMap)+countCodes(admDrugMap) }\")\n",
    "    print(f\" average Number of procedure code per visit {ListAvgVisit(admPxMap)}\")\n",
    "    print(f\" average Number of diagnosis code per visit {ListAvgVisit(admDxMap)}\")\n",
    "    print(f\" average Number of Drug code per visit {ListAvgVisit(admDrugMap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8e7cdc1-e313-4429-97ec-33528cb879cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(subject_idAdmMap : Dict[int, List[int]], admDxMap : Dict[int, List[str]], admPxMap : Dict[int, List[str]], admDrugMap : Dict[int, List[str]], min_admissions_threshold : int = 2) -> Tuple[Dict[int, List[int]], Dict[int, List[str]], Dict[int, List[str]], Dict[int, List[str]]]:\n",
    "    \"\"\"\n",
    "    Cleans the data by removing patient records that do not have all three medical codes for an admission\n",
    "    and removing patients who made less than a specified number of admissions.\n",
    "\n",
    "    Args:\n",
    "        subject_idAdmMap (dict): A dictionary mapping subject IDs to a list of admission IDs.\n",
    "        admDxMap (dict): A dictionary mapping admission IDs to diagnostic codes.\n",
    "        admPxMap (dict): A dictionary mapping admission IDs to procedure codes.\n",
    "        admDrugMap (dict): A dictionary mapping admission IDs to drug codes.\n",
    "        min_admissions_threshold (int, optional): The minimum number of admissions required for a patient to be included. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated subject_idAdmMap, adDx, adPx, and adDrug dictionaries.\n",
    "    \"\"\"\n",
    "    print(\"Cleaning data...\")\n",
    "    subDelList = []\n",
    "\n",
    "    print(\"Removing patient records who do not have all three medical codes for an admission\")\n",
    "    for subject_id, hadm_ids in subject_idAdmMap.items():\n",
    "        for hadm_id in hadm_ids:\n",
    "            if hadm_id not in admDxMap.keys():\n",
    "                subDelList.append(subject_id)\n",
    "            if hadm_id not in admPxMap.keys():\n",
    "                subDelList.append(subject_id)\n",
    "            if hadm_id not in admDrugMap.keys():\n",
    "                subDelList.append(subject_id)\n",
    "\n",
    "    subDelList = list(set(subDelList))\n",
    "\n",
    "    for subject_id_to_rm in subDelList:\n",
    "        del subject_idAdmMap[subject_id_to_rm]\n",
    "\n",
    "\n",
    "    adDx, adPx, adDrug = updateAdmCodeList(subject_idAdmMap, admDxMap, admPxMap, admDrugMap)\n",
    "\n",
    "    print(f\"Removing patients who made less than {min_admissions_threshold} admissions\")\n",
    "    pidMap = {}\n",
    "    adm = []\n",
    "    subDelList = []\n",
    "    subject_idAdmMap1 = subject_idAdmMap\n",
    "    for pid, admIdList in subject_idAdmMap.items():\n",
    "        if len(admIdList) < min_admissions_threshold:\n",
    "            subDelList.append(pid)\n",
    "            continue\n",
    "\n",
    "    for i in subDelList:\n",
    "        del subject_idAdmMap[i]\n",
    "\n",
    "    adDx, adPx, adDrug = updateAdmCodeList(subject_idAdmMap, adDx, adPx, adDrug)\n",
    "    display(subject_idAdmMap, adDx, adPx, adDrug)\n",
    "    return subject_idAdmMap, adDx, adPx, adDrug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c61c7e-e7bc-453d-b8ea-37272cd1bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CCS_CCSR_mapping(CCSRDX_file : str, CCSRPCS_file : str, CCSDX_file : str, CCSPX_file : str, dump : bool = True) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Creates a mapping of ICD-10 diagnosis and procedure codes to CCS tokens.\n",
    "\n",
    "    Args:\n",
    "        CCSRDX_file (str): The file path of the CCSRDX file containing ICD-10 diagnosis codes and CCS categories.\n",
    "        CCSRPCS_file (str): The file path of the CCSRPCS file containing ICD-10 procedure codes and CCS categories.\n",
    "        CCSDX_file (str): The file path of the CCSDX file containing ICD-9 diagnosis codes and CCS categories.\n",
    "        CCSPX_file (str): The file path of the CCSPX file containing ICD-9 procedure codes and CCS categories.\n",
    "        dump (bool, optional): Whether to dump the mapping dictionaries to pickle files. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping CCS codes to their descriptions.\n",
    "    \"\"\"\n",
    "    # This part creates an ICD-10 Diagnosis, Procedures map to CCS token list\n",
    "    df = pd.read_csv(CCSRDX_file)\n",
    "    a = df[[\"'ICD-10-CM CODE'\", \"'CCSR CATEGORY 1'\", \"'CCSR CATEGORY 2'\", \"'CCSR CATEGORY 3'\", \"'CCSR CATEGORY 4'\", \"'CCSR CATEGORY 5'\", \"'CCSR CATEGORY 6'\"]]\n",
    "\n",
    "    a = a.map(lambda x: str(x)[1:-1])\n",
    "\n",
    "    a = a.set_index(\"'ICD-10-CM CODE'\").T.to_dict('list')\n",
    "    # remove null values\n",
    "    for key, value in a.items():\n",
    "        newValue = []\n",
    "        value = list(filter(lambda x: x.strip(), value))\n",
    "        for value in value:\n",
    "            newValue.append('D10_' + value)\n",
    "        a[key] = newValue\n",
    "\n",
    "    b = {}\n",
    "    for key in a.keys():\n",
    "        new_key = 'D10_' + key\n",
    "        b[new_key] = a[key]\n",
    "\n",
    "    df = pd.read_csv(CCSRPCS_file, on_bad_lines='skip')\n",
    "    df = df[[\"'ICD-10-PCS'\", \"'PRCCSR'\"]]\n",
    "    df = df.map(lambda x: str(x)[1:-1])\n",
    "    df = df.set_index(\"'ICD-10-PCS'\").T.to_dict('list')\n",
    "\n",
    "    for key, value in df.items():\n",
    "        newValue = []\n",
    "        value = list(filter(lambda x: x.strip(), value))\n",
    "        for value in value:\n",
    "            newValue.append('P10_' + value)\n",
    "        df[key] = newValue\n",
    "\n",
    "    for key in df.keys():\n",
    "        new_key = 'P10_' + key\n",
    "        b[new_key] = df[key]\n",
    "\n",
    "    # ICD-9 diagnosis code and prescription to CCS\n",
    "    ccsTOdescription_Map = {}\n",
    "    dxref_ccs_file = open(CCSDX_file, 'r')\n",
    "    dxref_ccs_file.readline()  # note\n",
    "    dxref_ccs_file.readline()  # header\n",
    "    dxref_ccs_file.readline()  # null\n",
    "    for line in dxref_ccs_file:\n",
    "        tokens = line.strip().split(',')\n",
    "        b['D9_' + str(tokens[0][1:-1]).strip()] = 'D9_' + str(tokens[1][1:-1]).strip()\n",
    "        ccsTOdescription_Map['D9_' + str(tokens[1][1:-1]).strip()] = str(tokens[2][1:-1]).strip()\n",
    "    dxref_ccs_file.close()\n",
    "\n",
    "    dxprref_ccs_file = open(CCSPX_file, 'r')\n",
    "    dxprref_ccs_file.readline()  # note\n",
    "    dxprref_ccs_file.readline()  # header\n",
    "    dxprref_ccs_file.readline()  # null\n",
    "    for line in dxprref_ccs_file:\n",
    "        tokens = line.strip().split(',')\n",
    "        b['P9_' + str(tokens[0][1:-1]).strip()] = 'P9_' + str(tokens[1][1:-1]).strip()\n",
    "        ccsTOdescription_Map['P9_' + str(tokens[1][1:-1]).strip()] = str(tokens[2][1:-1]).strip()\n",
    "    dxprref_ccs_file.close()\n",
    "\n",
    "    if dump:\n",
    "        pickle.dump(b, open('ICD_9_10_to_CSS', 'wb'), -1)\n",
    "        pickle.dump(ccsTOdescription_Map, open('ccs_to_description_dictionary', 'wb'), -1)\n",
    "    print('Total ICD to CCS entries: ' + str(len(b)))\n",
    "    print('Total CCS codes/descriptions: ' + str(len(ccsTOdescription_Map)))\n",
    "\n",
    "    v1 = []\n",
    "    for v in b.values():\n",
    "        for val in v:\n",
    "            v1.append(val)\n",
    "    v1 = list(set(v1))\n",
    "    print(\"Total number of unique codes (Diag + Proc):\", len(v1))\n",
    "\n",
    "    return ccsTOdescription_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8adad64e-be25-4856-b1de-890da41939b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ccsr_description(filename: str, cat: str = 'Diag') -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Maps CCSR (Clinical Classifications Software Refined) category codes to their descriptions.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the Excel file containing the CCSR categories.\n",
    "        cat (str, optional): The category type ('Diag' or 'Proc'). Defaults to 'Diag'.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary mapping CCSR category codes to their descriptions.\n",
    "    \"\"\"\n",
    "    if cat == 'Diag':\n",
    "        padStr = 'D10_'\n",
    "    else:\n",
    "        padStr = 'P10_'\n",
    "    df = pd.read_excel(filename, sheet_name=\"CCSR_Categories\", skiprows=1)\n",
    "    if type != 'Diag':\n",
    "        df = df[:-1]\n",
    "    codeDescription = df[[\"CCSR Category\", \"CCSR Category Description\"]]\n",
    "    codeDescription = codeDescription.map(lambda x: padStr + str(x))\n",
    "    codeDescription = codeDescription.set_index(\"CCSR Category\").T.to_dict('list')\n",
    "    for key, value in codeDescription.items():\n",
    "        newValue = value[0][4:]\n",
    "        codeDescription[key] = newValue\n",
    "\n",
    "    return codeDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cde15d-93ae-4b9b-87d5-aba022dda008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convValuestoList(codeDic : Dict[str, str]) -> Dict[str, List[str]]:\n",
    "    for key, value in codeDic.items():\n",
    "        codeDic[key] =  [value]\n",
    "    return codeDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de3b056c-4171-4069-bf66-f4910b28062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ICD_to_CCSR(mapping : Dict[int, List[int]]) -> Tuple[Dict[int, List[str]], List[str], Set[str]]:\n",
    "    \"\"\"\n",
    "    Maps ICD codes to CCSR codes based on a given mapping.\n",
    "\n",
    "    Args:\n",
    "        mapping (Dict[int, List[int]]): A dictionary containing the mapping of hadm_id to a list of ICD codes.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[int, List[str]], List[str], Set[str]]: A tuple containing the following:\n",
    "            - CodesToInternalMap: A dictionary mapping hadm_id to a list of CCSR codes.\n",
    "            - missingCodes: A list of ICD codes that could not be mapped to CCSR codes.\n",
    "            - set_of_used_codes: A set of ICD codes that were successfully mapped to CCSR codes.\n",
    "    \"\"\"\n",
    "    \n",
    "    icdTOCCS_Map = pickle.load(open('ICD_9_10_to_CSS','rb'))\n",
    "    CodesToInternalMap = {}\n",
    "    missingCodes = []\n",
    "    set_of_used_codes = set()\n",
    "    number_of_codes_missing = 0\n",
    "    countICD9=0\n",
    "    countICD10 =0\n",
    "    for (hadm_id, ICDs_List) in mapping.items():\n",
    "        for ICD in ICDs_List:\n",
    "            #print(ICD,type(ICD),len(ICD))\n",
    "            #while (len(ICD9) < 6): ICD9 += ' '  #pad right white spaces because the CCS mapping uses this pattern\n",
    "            if ICD.startswith('D10_'):\n",
    "                padStr = 'D10_'\n",
    "            elif ICD.startswith('D9_'):\n",
    "                padStr = 'D9_'\n",
    "            elif ICD.startswith('P10_'):\n",
    "                padStr = 'P10_'    \n",
    "            elif ICD.startswith('P9_'):\n",
    "                padStr = 'P9_'  \n",
    "            else:\n",
    "                print(\"Wrong coding format\")\n",
    "\n",
    "            try:\n",
    "\n",
    "                CCS_code = icdTOCCS_Map[ICD]\n",
    "\n",
    "                if hadm_id in CodesToInternalMap:\n",
    "                    if(isinstance(CCS_code, str)): \n",
    "                        CodesToInternalMap[hadm_id].append(CCS_code)\n",
    "                    else:\n",
    "                        for code in CCS_code:\n",
    "                            CodesToInternalMap[hadm_id].append(code)\n",
    "                        \n",
    "                else:\n",
    "                    if(isinstance(CCS_code, str)): \n",
    "                        CodesToInternalMap[hadm_id] = [CCS_code]\n",
    "                    else:\n",
    "                        for i in range(len(CCS_code)):\n",
    "                            if i==0:\n",
    "                                CodesToInternalMap[hadm_id] = [CCS_code[i]]\n",
    "                            else:\n",
    "                                CodesToInternalMap[hadm_id].append(CCS_code[i])\n",
    "                                \n",
    "                            \n",
    "                set_of_used_codes.add(ICD)\n",
    "\n",
    "            except KeyError:\n",
    "                #print(f\"the mapping of {ICD} {hadm_id}\")\n",
    "                missingCodes.append(ICD)\n",
    "                #print(f\"the mapping of  is : {icdTOCCS_Map[ICD]}\")\n",
    "                number_of_codes_missing +=1\n",
    "                #print (str(sys.exc_info()[0]) + '  ' + str(ICD) + \". ICD9 code not found, please verify your ICD9 to CCS mapping before proceeding.\")\n",
    "\n",
    "\n",
    "            \n",
    "    print(f\"total number of ICD9 codes used {countICD9} and ICD10 codes: {countICD10}\")  \n",
    "    print ('-Total number (complete set) of ICD9+ICD10 codes (diag + proc): ' + str(len(set(icdTOCCS_Map.keys()))))\n",
    "    #print ('-Total number (complete set) of CCS codes (diag + proc): ' + str(len(set(icd9TOCCS_Map.values()))))\n",
    "    print ('-Total number of ICD codes actually used: ' + str(len(set_of_used_codes)))\n",
    "    print ('-Total number of ICD codes missing in the admissions list: ' , number_of_codes_missing)\n",
    "    #print(icd9TOCCS_Map)\n",
    "    \n",
    "    return CodesToInternalMap,missingCodes,set_of_used_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80baa3b5-15c4-4492-b478-77f82ee74859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCodeStats(adDx : ,adPx,adDrug):\n",
    "    print(f\" Total Number of diagnosis code {countCodes(adDx)}\")\n",
    "    print(f\" Total Number of procedure code {countCodes(adPx)}\")\n",
    "    print(f\" Total Number of drug code {countCodes(adDrug)}\")\n",
    "    print(f\" Total Number of unique  D,P codes {countCodes(adDx,adPx) }\")\n",
    "    print(f\" Total Number of all codes {countCodes(adDx,adPx,adDrug) }\")\n",
    "\n",
    "\n",
    "    print(f\" average Number of procedure code per visit {ListAvgVisit(adPx)}\")\n",
    "    print(f\" average Number of diagnosis code per visit {ListAvgVisit(adDx)}\")\n",
    "    print(f\" average Number of drug code per visit {ListAvgVisit(adDrug)}\")\n",
    "\n",
    "    print(f\" Min. and max. Number of diagnosis code per admission {minMaxCodes(adDx)}\")\n",
    "    print(f\" Min. and max. Number of procedure code  per admission{minMaxCodes(adPx)}\")\n",
    "    print(f\" Min. and max. Number of drug code  per admission {minMaxCodes(adDrug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f832216c-b02d-4551-8be8-f15d71afe6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minMaxCodes(dic):\n",
    "    countCode = []\n",
    "    for codes in dic.values():\n",
    "        countCode.append(len(codes))    \n",
    "                \n",
    "    return min(countCode),max(countCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e1347c-30c8-4170-8520-51245dc2769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd_mapping(CCSRDX_file: str, CCSRPCS_file: str, CCSDX_file: str, CCSPX_file: str, D_CCSR_Ref_file: str, P_CCSR_Ref_file: str, adDx: Dict[int, List[int]], adPx: Dict[int, List[int]], adDrug: Dict[int, List[int]], drugDescription: Dict[str, str]) -> Tuple[Dict[int, List[int]], Dict[int, List[int]], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Maps ICD codes to CCS and CCSR codes and returns the mapped diagnosis codes, procedure codes, and code descriptions.\n",
    "\n",
    "    Parameters:\n",
    "    - CCSRDX_file (str): Path to the CCSRDX file.\n",
    "    - CCSRPCS_file (str): Path to the CCSRPCS file.\n",
    "    - CCSDX_file (str): Path to the CCSDX file.\n",
    "    - CCSPX_file (str): Path to the CCSPX file.\n",
    "    - D_CCSR_Ref_file (str): Path to the D_CCSR_Ref file.\n",
    "    - P_CCSR_Ref_file (str): Path to the P_CCSR_Ref file.\n",
    "    - adDx (Dict[int, List[int]]): Dictionary containing the diagnosis codes.\n",
    "    - adPx (Dict[int, List[int]]): Dictionary containing the procedure codes.\n",
    "    - adDrug (Dict[int, List[int]]): Dictionary containing the drug codes.\n",
    "    - drugDescription (Dict[str, str]): Dictionary containing the descriptions of drug codes.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[Dict[int, List[int]], Dict[int, List[int]], Dict[str, str]]: A tuple containing the mapped diagnosis codes, procedure codes, and code descriptions.\n",
    "    \"\"\"\n",
    "    # creating mappint between all ICD codes to CCS and CCSR mapping\n",
    "    ccsTOdescription_Map = create_CCS_CCSR_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file)\n",
    "    # getting the description of all codes\n",
    "    DxcodeDescription = map_ccsr_description(D_CCSR_Ref_file)\n",
    "    PxcodeDescription = map_ccsr_description(P_CCSR_Ref_file, cat = 'Proc')\n",
    "    codeDescription ={**DxcodeDescription ,**PxcodeDescription }\n",
    "    codeDescription ={**codeDescription , **convValuestoList(ccsTOdescription_Map), **drugDescription}\n",
    "    # mapping diagnois codes\n",
    "    adDx,missingDxCodes,set_of_used_codes1 = map_ICD_to_CCSR(adDx)\n",
    "    # mapping procedure codes\n",
    "    print('here it should be working')\n",
    "    print(adPx[23384508])\n",
    "    print('---------------')\n",
    "    adPx,missingPxCodes,set_of_used_codes2 = map_ICD_to_CCSR(adPx)\n",
    "    print( 'P10_0QS604Z' in missingPxCodes)\n",
    "    codeDescription['SOH'] = 'Start of history'\n",
    "    codeDescription['EOH'] = 'End of history'\n",
    "    codeDescription['BOV'] = 'Beginning of visit'\n",
    "    codeDescription['EOV'] = 'End of visit'\n",
    "    codeDescription['BOS'] = 'Beginning of sequence'\n",
    "    codeDescription['PAD'] = 'Padding'\n",
    "    displayCodeStats(adDx,adPx,adDrug)\n",
    "    return adDx,adPx,codeDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a62ff81-85a8-4548-8f33-e07108809b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(adDx  : Dict[int,List[int]], adPx  : Dict[int,List[int]], adDrug  : Dict[int,List[int]], min_dxm : int, min_px : int, min_drg: int) -> Tuple[Dict[int,List[int]], Dict[int,List[int]], Dict[int,List[int]]]:\n",
    "    \"\"\"\n",
    "    Trims the diagnosis, procedure, and medication codes for each visit.\n",
    "\n",
    "    Parameters:\n",
    "    adDx (dict): A dictionary containing admission IDs as keys and diagnosis codes as values.\n",
    "    adPx (dict): A dictionary containing admission IDs as keys and procedure codes as values.\n",
    "    adDrug (dict): A dictionary containing admission IDs as keys and medication codes as values.\n",
    "    min_dxm (int): The minimum number of diagnosis codes to keep for each admission.\n",
    "    min_px (int): The minimum number of procedure codes to keep for each admission.\n",
    "    min_drg (int): The minimum number of medication codes to keep for each admission.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the trimmed dictionaries for diagnosis codes, procedure codes, and medication codes.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Trimming the diagnosis, procedure, and medication codes for each visit\")\n",
    "    \n",
    "    for admission, DiagCodes in adDx.items():\n",
    "        adDx[admission] = DiagCodes[:min_dx]\n",
    "        \n",
    "    for admission, ProcCodes in adPx.items():\n",
    "        adPx[admission] = ProcCodes[:min_px]\n",
    "        \n",
    "    for admission, DrugCodes in adDrug.items():\n",
    "        adDrug[admission] = DrugCodes[:min_drg]\n",
    "        \n",
    "    displayCodeStats(adDx, adPx, adDrug)\n",
    "    return adDx, adPx, adDrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fd9d2be-cbbf-4e92-8146-ea6cd46007bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildData(subject_idAdmMap : Dict[int, List[int]], adDx: Dict[int, List[int]], adPx: Dict[int, List[int]], adDrug: Dict[int, List[int]], minVisits: int = 2) -> Tuple[List[List[List[int]]], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Builds the data for patient trajectory forecasting.\n",
    "\n",
    "    Args:\n",
    "        subject_idAdmMap (dict): A dictionary mapping subject IDs to admission IDs.\n",
    "        adDx (dict): A dictionary mapping admission IDs to diagnosis codes.\n",
    "        adPx (dict): A dictionary mapping admission IDs to procedure codes.\n",
    "        adDrug (dict): A dictionary mapping admission IDs to drug codes.\n",
    "        minVisits (int, optional): The minimum number of visits required for a patient. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[List[int]]], Dict[str, int]]: A tuple containing the processed patient sequences and the code types dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    adPx, adDx, adDrug = map(lambda d: defaultdict(list, d), (adPx, adDx, adDrug)) # add default [] for missing values\n",
    "\n",
    "    print(f'Building admission-Visits mapping & filtering patients with less than {minVisits} ')\n",
    "    pidSeqMap = {}\n",
    "    \n",
    "    skipped = 0 \n",
    "    for subject_id, admIdList in subject_idAdmMap.items():\n",
    "        if len(admIdList) < minVisits: \n",
    "            skipped += 1\n",
    "            continue # skip patients with less than minVisits ( default 1 )\n",
    "        sortedList = [(adDx[admId], adPx[admId], adDrug[admId]) for admId in admIdList]\n",
    "        \n",
    "        pidSeqMap[subject_id] = sortedList\n",
    "        \n",
    "    adPx, adDx, adDrug = map(dict, (adPx, adDx, adDrug))  # remove default [] behavior to not break something\n",
    "\n",
    "    print(f'{skipped} subjects were removed')\n",
    "    print('Building subject-id, diagnosis, procedure, drugs mapping')\n",
    "    subject_ids = []\n",
    "    dates = []\n",
    "    seqs = []\n",
    "    ages = []\n",
    "    for subject_id, visits in pidSeqMap.items():\n",
    "        subject_ids.append(subject_id)\n",
    "        diagnose = []\n",
    "        procedure = []\n",
    "        drugs = []\n",
    "        date = []\n",
    "        seq = []\n",
    "        for visit in visits:\n",
    "            joined = list(dict.fromkeys(chain.from_iterable(visit))) # dict.fromkeys used as an ordered set func\n",
    "            seq.append(joined)\n",
    "        seqs.append(seq)\n",
    "\n",
    "    print('Converting Strings Codes into unique integer, and making types')\n",
    "    types = {}\n",
    "    newSeqs = []\n",
    "    for patient in seqs:\n",
    "        newPatient = []\n",
    "        #print(\"patient\",patient)\n",
    "        for visit in patient:\n",
    "            #print(\"visit\",visit)\n",
    "            newVisit = []\n",
    "            for code in visit:\n",
    "                #print(\"code\",code)\n",
    "                if code in types:\n",
    "                    newVisit.append(types[code])\n",
    "                else:\n",
    "                    types[code] = len(types)\n",
    "                    newVisit.append(types[code])\n",
    "                    #print(\"newVisit\",newVisit)\n",
    "            newPatient.append(newVisit)\n",
    "        newSeqs.append(newPatient)\n",
    "    return newSeqs, types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daad9149-170b-413b-9ec3-87ab07ecb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListAvgVisitForRemoveCode(dic):\n",
    "    a =[len(intList) for intList in dic]\n",
    "    return sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4e95a03-95cf-4cab-8310-4beb68d7a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCode(currentSeqs : List[List[List[int]]], types, threshold :int = 5) -> Tuple[List[List[List[int]]], Dict[str, int], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Removes infrequent codes from the given sequences.\n",
    "\n",
    "    Args:\n",
    "        currentSeqs (List[List[List[int]]]): The input sequences containing codes.\n",
    "        types (Dict[str, int]): A dictionary mapping code types to their corresponding integer values.\n",
    "        threshold (int, optional): The threshold value for removing infrequent codes. Codes with a count less than or equal to this threshold will be removed. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[List[int]]], Dict[str, int], Dict[int, str]]: A tuple containing the updated sequences, the updated types dictionary, and the reverse types dictionary.\n",
    "    \"\"\"\n",
    "    countCode = Counter()\n",
    "    \n",
    "    for visits in currentSeqs:\n",
    "        for visit in visits:\n",
    "            countCode.update(visit)\n",
    "            \n",
    "    codes = [key for key, value in countCode.items() if value <= threshold]\n",
    "    \n",
    "    print(f\" Total number of codes removed: {len(codes)}  \")\n",
    "    print(f\" Total number of  unique codes : {len(countCode)}  \")\n",
    "\n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "\n",
    "    # List of codes like : D9_660...\n",
    "    types = defaultdict(lambda: len(types), {\"PAD\": 0,\"BOH\":1 ,\"BOS\": 2, \"BOV\": 3, \"EOV\": 4, \"EOH\": 5})\n",
    "\n",
    "    # Recreates a new mapping while taking into consideration the removed tokens\n",
    "    updatedSeqs = [[[types[reverseTypes[code]] for code in visit if code not in codes] for visit in patient] for patient in currentSeqs]\n",
    "    \n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "\n",
    "    return updatedSeqs, dict(types), reverseTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cdd0d6f-53ea-46ad-87b1-b0711a38913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFiles(updatedSeqs : List[List[List[int]]], types, codeDescription : str, outpath : str = 'outputData/originalData'):\n",
    "    \"\"\"\n",
    "    Save the updated sequences, types, and code description to files.\n",
    "\n",
    "    Parameters:\n",
    "    updatedSeqs (List[List[List[int]]]): The updated sequences to be saved.\n",
    "    types: The types to be saved.\n",
    "    codeDescription (str): The code description to be saved.\n",
    "    outpath (str, optional): The output path where the files will be saved. Defaults to 'outputData/originalData'.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    pickle.dump(updatedSeqs, open(outFile+'.seqs', 'wb'), -1)\n",
    "    pickle.dump(types, open(outFile+'.types', 'wb'), -1)\n",
    "    pickle.dump(codeDescription, open(outFile+'.description', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f417c2d9-09d2-46fe-b680-2ed4ef8c4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCodeTypes(outFile: str, reverseTypes: Dict[int, str]) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Generate code types based on reverse types dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - outFile (str): The name of the output file.\n",
    "    - reverseTypes (Dict[int, str]): A dictionary containing reverse types.\n",
    "\n",
    "    Returns:\n",
    "    - codeType (Dict[str, int]): A dictionary containing the generated code types.\n",
    "    \"\"\"\n",
    "    ICD_9_10_to_CSS = pickle.load(open('ICD_9_10_to_CSS', 'rb'))\n",
    "    codeType = {}\n",
    "    countD = 0\n",
    "    countP = 0\n",
    "    countDr = 0\n",
    "    countT = 0\n",
    "\n",
    "    for keys, values in reverseTypes.items():\n",
    "        found = 0\n",
    "        if keys not in codeType:\n",
    "            if values.startswith('DR_'):\n",
    "                found = 1\n",
    "                codeType[keys] = 'DR'\n",
    "                countDr = countDr + 1\n",
    "            elif values == 'PAD' or values == 'BOH' or values == \"BOS\" or values == 'BOV' or values == 'EOV' or values == 'EOH':\n",
    "                found = 1\n",
    "                codeType[keys] = 'T'\n",
    "                countT = countT + 1\n",
    "            else:\n",
    "                for k, v in ICD_9_10_to_CSS.items():\n",
    "                    if values in v:\n",
    "                        found = 1\n",
    "                        if keys not in codeType:\n",
    "                            if k.startswith('D'):\n",
    "                                codeType[keys] = 'D'\n",
    "                                countD = countD + 1\n",
    "                            elif k.startswith('P'):\n",
    "                                codeType[keys] = 'P'\n",
    "                                countP = countP + 1\n",
    "            if found == 0:\n",
    "                print(keys, values)\n",
    "\n",
    "    print(countD, countP, countDr, countT)\n",
    "    pickle.dump(codeType, open(outFile + '.codeType', 'wb'), -1)\n",
    "\n",
    "    return codeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61e1ac9f-aa3d-4f88-af4d-1fed4ea9ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(outFile : str) -> Tuple[List[List[List[int]]], Dict[str, ], Dict[str, int], Dict[int, str]]:\n",
    "    # load the data again\n",
    "    seqs = pickle.load(open(outFile +'.seqs','rb'))\n",
    "    types = pickle.load(open(outFile + '.types','rb'))\n",
    "    codeType = pickle.load(open(outFile + '.codeType','rb'))\n",
    "    reverseTypes = {v:k for k,v in types.items()}\n",
    "    return seqs,types,codeType,reverseTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad80bd71-420f-49e7-bd39-a71115e61ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForTF(sequence : List[List[int]]) -> Tuple[List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Prepares the input sequence for trajectory forecasting training by creating pairs of input and output sequences.\n",
    "\n",
    "    Args:\n",
    "        sequence (List[List[int]]): The input sequence of integers.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[List[List[int]], List[List[int]]]]: A list of pairs, where each pair consists of an input sequence and its corresponding output sequence.\n",
    "    \"\"\"\n",
    "    X, y, pairs = list(), list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        if i+1 >= len(sequence):\n",
    "            break\n",
    "        X.append(sequence[:i+1])\n",
    "        y.append(sequence[i+1:])\n",
    "    pairs = pairing1(X, y)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa1a9c6d-db94-4a1c-b0d1-a3f6a8f57860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareForSDP(sequence: List[List[int]]):\n",
    "    \"\"\"\n",
    "    Prepare the sequence for Sequential disease prediction modeling.\n",
    "\n",
    "    Args:\n",
    "        sequence (list): The input sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of pairs containing the input sequence and the corresponding target sequence.\n",
    "\n",
    "    \"\"\"\n",
    "    X, y, pairs = list(), list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        if i + 1 >= len(sequence):\n",
    "            break\n",
    "        X.append(sequence[:i+1])\n",
    "        y.append([sequence[i+1]])\n",
    "    pairs = pairing1(X, y)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae4f8d20-4431-4c4d-8254-d9064b34bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePairs(newPairs, mn = 600):\n",
    "    print(f\"\\n  Total no of pairs before removing :{len(newPairs)}\")\n",
    "    b = len(newPairs)\n",
    "    x,y,curPair = [],[],[]\n",
    "    count,county,counts =0,0,0\n",
    "    for pair in newPairs:\n",
    "        if len(pair[0]) > mn and len(pair[1]) > mn:\n",
    "            counts =counts +1\n",
    "            #newPairs.remove(pair)   \n",
    "        elif len(pair[0]) > mn or len(pair[1]) > mn:\n",
    "            count =count +1\n",
    "            #newPairs.remove(pair)\n",
    "        else:\n",
    "            curPair.append(pair)\n",
    "            \n",
    "    print(f\"\\n  Total no of pairs after removing :{len(curPair)}\")\n",
    "    print(f\"\\n  Total no of pairs removed :{b-len(curPair)}\")\n",
    "    return curPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "106ca9ca-f979-472a-93d0-f9dc7e14acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(originalSeqs : List[List[List[int]]], dataFormat : str = 'TF', mn : int = 400) -> List[Tuple[List[List[int]]]]:\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(len(originalSeqs)):\n",
    "        # Trajectory forecasting (TF): predict until the end of EOH\n",
    "        if dataFormat == 'TF':\n",
    "            pairs.extend(PrepareForTF(originalSeqs[i]))\n",
    "        # Sequential disease prediction (SDP): predict until the next visit\n",
    "        elif dataFormat == 'SDP':\n",
    "            pairs.extend(PrepareForSDP(originalSeqs[i]))\n",
    "        else:\n",
    "            raise \n",
    "            \n",
    "    newPairs, p = [], []\n",
    "\n",
    "    for pair in pairs:\n",
    "        #print(\"paiot\",pair)\n",
    "        inputs,output,p =[],[],[]\n",
    "        for i in pair[0]:\n",
    "            #print(\"i\",i)\n",
    "            i = i +[2]\n",
    "            inputs.extend(i)\n",
    "        p.append([1]+ inputs + [3])\n",
    "        for o in pair[1]:\n",
    "            o = o +[2]\n",
    "            #print(\"o\",o)\n",
    "            output.extend(o)\n",
    "        p.append([1]+ output+ [3])\n",
    "\n",
    "        newPairs.append(tuple(p))\n",
    "        \n",
    "    if(stats(newPairs, mn = mn)):\n",
    "        print(f\"\\n\\n\\nRemoving pairs greater than  {mn} seq length\")\n",
    "        newPairs = removePairs(newPairs,mn=mn)\n",
    "        stats(newPairs)\n",
    "    return newPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "862bb4d2-59f7-4ecc-ac6b-61241e886e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing1(x : List[List[int]], y : List[List[int]]) -> List[Tuple[List[int],List[int]]]:\n",
    "    pairs = []\n",
    "    for i, a in enumerate(zip(x,y)):\n",
    "        pairs.append(a)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4ec046d-5f82-49e4-babd-216e3ca42bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(newPairs,mn : int = 600):\n",
    "    x, y = [],[]\n",
    "    count, county, counts = 0, 0, 0\n",
    "    for pair in newPairs:\n",
    "        if len(pair[0]) > mn:\n",
    "            count = count +1\n",
    "\n",
    "        if len(pair[1]) > mn:\n",
    "            county = county +1 \n",
    "\n",
    "        if len(pair[0])>mn and len(pair[1])  > mn:\n",
    "            counts = counts +1\n",
    "        x.append(len(pair[0]))\n",
    "        y.append(len(pair[1]))\n",
    "        \n",
    "    if count > 0 or county > 0 or counts > 0:\n",
    "        run = True\n",
    "    else:\n",
    "        run = False\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bfadec4-9355-4ade-9524-e0cc1ef04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetIntegerOutput(updSeqs,isall : int = 1):\n",
    "    # updating the output codes to reduce hypothesis space as some of the medical codes have been removed.\n",
    "    # outTypes = {prev-codes : new-codes} ,  token codes remain same \n",
    "    updPair = []\n",
    "    outTypes = {}\n",
    "    outTypes.update({0:0 , 1:1,  2:2, 3:3})\n",
    "    for i,pair in enumerate(updSeqs):\n",
    "        newVisit = []\n",
    "        for code in pair[1]:\n",
    "            if code in outTypes:\n",
    "                newVisit.append(outTypes[code])\n",
    "            else:\n",
    "                outTypes[code] = len(outTypes)\n",
    "                newVisit.append(outTypes[code])\n",
    "        updPair.append((pair[0],newVisit))\n",
    "    return updPair, outTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c552d0-2bf8-48ae-8bf4-43bc402819f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateOutput(newPairs, codeType, diagnosis=0, procedure=0, drugs =0, all = 0):\n",
    "    updSeqs = []\n",
    "    if procedure == 1 and drugs == 1:\n",
    "        print(\"\\n Removing drug and procedure codes from output for forecasting diagnosis code only\")\n",
    "        for i,pair in enumerate(newPairs):\n",
    "            newOutput = []\n",
    "            for code in pair[1]:\n",
    "                if (codeType[code] =='D' or codeType[code] =='T'):\n",
    "                    newOutput.append(code)\n",
    "                        \n",
    "            if len(newOutput) >= 4:\n",
    "            #print(f\"{newOutput} \\n\")\n",
    "                updSeqs.append((pair[0],newOutput))\n",
    "    if drugs == 1 and procedure == 0:\n",
    "        print(\"\\n Removing only drug codes from output for forecasting diagnosis and procedure code only\")\n",
    "        for i,pair in enumerate(newPairs):\n",
    "            newOutput = []\n",
    "            for code in pair[1]:\n",
    "                if not (codeType[code] == 'DR'):\n",
    "                    newOutput.append(code)\n",
    "            if len(newOutput)>=4:\n",
    "                updSeqs.append((pair[0],newOutput))\n",
    "    if all:\n",
    "        print(\"\\n keeping all codes\")\n",
    "        updSeqs = newPairs.copy()\n",
    "        \n",
    "    return updSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d282296-f466-446f-af21-5df54eac48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeFiles(pair,outTypes,codeType,types,reverseTypes,outFile):\n",
    "    if not os.path.exists(outFile):\n",
    "        os.makedirs(outFile)\n",
    "    pickle.dump(pair, open(outFile+'.seqs', 'wb'), -1)\n",
    "    pickle.dump(outTypes, open(outFile+'.outTypes', 'wb'), -1)\n",
    "    pickle.dump(codeType, open(outFile+'.codeType', 'wb'), -1)\n",
    "    pickle.dump(types, open(outFile+'.types', 'wb'), -1)\n",
    "    pickle.dump(reverseTypes, open(outFile+'.reverseTypes', 'wb'), -1)\n",
    "    reverseOutTypes = {v:k for k,v in outTypes.items()}\n",
    "    pickle.dump(reverseOutTypes, open(outFile+'.reverseTypes', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dab48b6-1a49-4c4b-958e-ca9999421eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCS_DIR = './CSS/'\n",
    "\n",
    "CCSRDX_file = os.path.join(CCS_DIR, 'DXCCSR_v2021-2.csv')\n",
    "CCSRPCS_file = os.path.join(CCS_DIR, 'PRCCSR_v2021-1.CSV')\n",
    "\n",
    "CCSDX_file = os.path.join(CCS_DIR, '$dxref 2015.csv')\n",
    "CCSPX_file = os.path.join(CCS_DIR, '$prref 2015.csv')\n",
    "\n",
    "D_CCSR_Ref_file = os.path.join(CCS_DIR, 'DXCCSR-Reference-File-v2021-2.xlsx')\n",
    "P_CCSR_Ref_file = os.path.join(CCS_DIR, 'PRCCSR-Reference-File-v2021-1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd0ddd50-c233-4d21-a371-d508b880fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Building subject_id-admission mapping, admission-date mapping\n",
      "Building admission-diagnosis mapping\n",
      "-Number of null ICD9 codes in file mimic-iv-2.2/hosp/diagnoses_icd.csv.gz: 0\n",
      "-Number of null ICD10 codes in file mimic-iv-2.2/hosp/diagnoses_icd.csv.gz: 0\n",
      "Building admission-procedure mapping\n",
      "-Number of null ICD9 codes in file mimic-iv-2.2/hosp/procedures_icd.csv.gz: 0\n",
      "-Number of null ICD10 codes in file mimic-iv-2.2/hosp/procedures_icd.csv.gz: 0\n",
      "Building admission-drug mapping\n",
      "\n",
      " Completed...\n",
      "\n",
      " Cleaning data...\n",
      "Cleaning data...\n",
      "Removing patient records who does not have all three medical codes for an admission\n",
      "Removing patient who made less than 2 admissions\n",
      " Total Number of patients 19834\n",
      " Total Number of admissions 52957\n",
      " Average number of admissions per patient 2.6700110920641325\n",
      " Total Number of diagnosis code 14119\n",
      " Total Number of procedure code 7511\n",
      " Total Number of drug code 4891\n",
      " Total Number of codes 26521\n",
      " average Number of procedure code per visit 3.081991049341919\n",
      " average Number of diagnosis code per visit 11.927412806616688\n",
      " average Number of Drug code per visit 50.46753026039995\n",
      "\n",
      " Completed...\n",
      "\n",
      "Mapping ICD data to CCS and CCSR...\n",
      "Total ICD to ccs entries: 144424\n",
      "Total ccs codes/descriptions: 514\n",
      "total number of unqiue codes(DIag + proc): 828\n",
      "total number of ICD9 codes used 0 and ICD10 codes: 0\n",
      "-Total number (complete set) of ICD9+ICD10 codes (diag + proc): 144424\n",
      "-Total number of ICD codes actually used: 14112\n",
      "-Total number of ICD codes missing in the admissions list:  7\n",
      "here it should be working\n",
      "['P10_0QS604Z']\n",
      "---------------\n",
      "total number of ICD9 codes used 0 and ICD10 codes: 0\n",
      "-Total number (complete set) of ICD9+ICD10 codes (diag + proc): 144424\n",
      "-Total number of ICD codes actually used: 5773\n",
      "-Total number of ICD codes missing in the admissions list:  8170\n",
      "True\n",
      " Total Number of diagnosis code 754\n",
      " Total Number of procedure code 466\n",
      " Total Number of drug code 4891\n",
      " Total Number of unique  D,P codes 1220\n",
      " Total Number of all codes 6111\n",
      " average Number of procedure code per visit 3.0384502322299958\n",
      " average Number of diagnosis code per visit 12.549105878354137\n",
      " average Number of drug code per visit 50.46753026039995\n",
      " Min. and max. Number of diagnosis code per admission (1, 56)\n",
      " Min. and max. Number of procedure code  per admission(1, 41)\n",
      " Min. and max. Number of drug code  per admission (1, 1202)\n",
      "\n",
      " Completed...\n",
      "\n",
      " Trimming the codes assigned per visit based on a threshold...\n",
      "Trimming the diagnosis, procedure, and medication codes for each visit\n",
      " Total Number of diagnosis code 754\n",
      " Total Number of procedure code 466\n",
      " Total Number of drug code 4787\n",
      " Total Number of unique  D,P codes 1220\n",
      " Total Number of all codes 6007\n",
      " average Number of procedure code per visit 3.0384502322299958\n",
      " average Number of diagnosis code per visit 12.549105878354137\n",
      " average Number of drug code per visit 38.60158241592235\n",
      " Min. and max. Number of diagnosis code per admission (1, 56)\n",
      " Min. and max. Number of procedure code  per admission(1, 41)\n",
      " Min. and max. Number of drug code  per admission (1, 80)\n",
      "\n",
      " Completed...\n",
      "\n",
      " Building the data..\n",
      "Building admission-Visits mapping & filtering patients with less than 2 \n",
      "0 subjects were removed\n",
      "Building subject-id, diagnosis,procedure,drugs mapping\n",
      "Converting Strings Codes into unique integer, and making types\n",
      "\n",
      " removing the code whose occurence is less than a certain threshold: 5\n",
      "2.6700110920641325\n",
      " Total number of codes removed: 1521  \n",
      " Total number of  unique codes : 6007  \n",
      "\n",
      " Save the data before formmating based on the task\n",
      "691 424 3371 6\n",
      "\n",
      " Completed...\n",
      "\n",
      " Preparing data for Trajectory Forecasting....\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32571\n",
      "\n",
      "  Total no of pairs removed :552\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32571\n",
      "\n",
      "  Total no of pairs removed :552\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " Removing only drug codes from output for forecasting diagnosis and procedure code only\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " keeping all codes\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " Removing only drug codes from output for forecasting diagnosis and procedure code only\n",
      "\n",
      " total # S1 records : 32570\n",
      " total # S2 records :32571\n",
      " total # S3 records :32571\n",
      "\n",
      " total Dx codes:695 \n",
      "  total Dx,Px codes:1119 \n",
      " total Dx,Px,Rx codes:4490\n",
      "\n",
      " Storing all the information related to Trajectory Forecasting...\n",
      "\n",
      " Completed...\n",
      "\n",
      "Preparing data for Sequential disease prediction....\n",
      "\n",
      "\n",
      "\n",
      "Removing pairs greater than  500 seq length\n",
      "\n",
      "  Total no of pairs before removing :33123\n",
      "\n",
      "  Total no of pairs after removing :32808\n",
      "\n",
      "  Total no of pairs removed :315\n",
      "\n",
      "\n",
      " Remove certain codes from output for different data formats\n",
      "\n",
      " Removing drug and procedure codes from output for forecasting diagnosis code only\n",
      "\n",
      " total # records: 32807 \n",
      " total # of codes: 695\n",
      "\n",
      " Storing all the information related to TSequential disease prediction...\n",
      "\n",
      " Completed...\n",
      "\n",
      " All the preprocessing step has been completed, Now use the data in the outputData folder to build the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the data...\")\n",
    "subject_idAdmMap,admDxMap,admPxMap,admDrugMap,drugDescription = load_mimic_data()\n",
    "print(\"\\n Completed...\")\n",
    "#stage 2 and 3\n",
    "print(\"\\n Cleaning data...\")\n",
    "subject_idAdmMap,adDx,adPx,adDrug = clean_data(subject_idAdmMap,admDxMap,admPxMap,admDrugMap)\n",
    "print(\"\\n Completed...\")\n",
    "#stage 4\n",
    "print(\"\\nMapping ICD data to CCS and CCSR...\")\n",
    "adDx,adPx,codeDescription = icd_mapping(CCSRDX_file,CCSRPCS_file,CCSDX_file,CCSPX_file,D_CCSR_Ref_file,P_CCSR_Ref_file,adDx,adPx,adDrug,drugDescription)\n",
    "print(\"\\n Completed...\")\n",
    "#stage 5\n",
    "print(\"\\n Trimming the codes assigned per visit based on a threshold...\")\n",
    "min_dx, min_px, min_drg = 80, 80, 80 \n",
    "adDx, adPx, adDrug= trim(adDx, adPx, adDrug, min_dx, min_px, min_drg)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n Building the data..\")\n",
    "newSeqs,types=buildData(subject_idAdmMap,adDx,adPx,adDrug)\n",
    "#stage 6\n",
    "threshold = 5\n",
    "print(f\"\\n removing the code whose occurence is less than a certain threshold: {threshold}\")\n",
    "updatedSeqs ,types ,reverseTypes  = removeCode(newSeqs,types,threshold=threshold)\n",
    "# outFile - is a folder path in the working directory where the data is going to get stored\n",
    "outFile = os.path.join('outputData','originalData')\n",
    "print(\"\\n Save the data before formmating based on the task\")\n",
    "saveFiles(updatedSeqs,dict(types),codeDescription)\n",
    "codeType = generateCodeTypes(outFile,reverseTypes)\n",
    "seqs,types,codeType,reverseTypes = load_data(outFile)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n Preparing data for Trajectory Forecasting....\")\n",
    "# sequence length threshold  -mn\n",
    "seqLength = 500\n",
    "newPairs = formatData(seqs,dataFormat = 'TF', mn = seqLength)\n",
    "diagnosisOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d')\n",
    "diagnosisProcedureOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p')\n",
    "AllOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p_dr')\n",
    "# sequence length threshold  -mn\n",
    "seqLength = 500\n",
    "newPairs = formatData(seqs,dataFormat = 'TF', mn = seqLength)\n",
    "diagnosisOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d')\n",
    "diagnosisProcedureOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p')\n",
    "AllOutputFile = os.path.join('outputData','TF','Inp_d_p_dr_out_d_p_dr')\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "print(f\"\\n Remove certain codes from output for different data formats\")\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "diagnosisProcedureUpdPair,diagnosisProcedureOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =1,all =0))\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "print(f\"\\n Remove certain codes from output for different data formats\")\n",
    "AllUpdPair,AllOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =0,all =1))\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "diagnosisProcedureUpdPair,diagnosisProcedureOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=0,drugs =1,all =0))\n",
    "\n",
    "print(f\"\\n total # S1 records : {len(diagnosisUpdPair)}\\n total # S2 records :{len(diagnosisProcedureUpdPair)}\\n total # S3 records :{len(AllUpdPair)}\")\n",
    "print(f\"\\n total Dx codes:{len(diagnosisOutTypes)} \\n  total Dx,Px codes:{len(diagnosisProcedureOutTypes)} \\n total Dx,Px,Rx codes:{len(AllOutTypes)}\")\n",
    "print(\"\\n Storing all the information related to Trajectory Forecasting...\")\n",
    "\n",
    "\n",
    "storeFiles(diagnosisUpdPair,diagnosisOutTypes,codeType,types,reverseTypes,diagnosisOutputFile)\n",
    "storeFiles(diagnosisProcedureUpdPair,diagnosisProcedureOutTypes,codeType,types,reverseTypes,diagnosisProcedureOutputFile)\n",
    "storeFiles(AllUpdPair,AllOutTypes,codeType,types,reverseTypes,AllOutputFile)\n",
    "print(\"\\n Completed...\")\n",
    "\n",
    "print(\"\\nPreparing data for Sequential disease prediction....\")\n",
    "newPairs = formatData(seqs,dataFormat = 'SDP',mn =500)\n",
    "diagnosisOutputFile = os.path.join('outputData','SDP','Inp_d_p_dr_out_d')\n",
    "\n",
    "print(f\"\\n\\n Remove certain codes from output for different data formats\")\n",
    "diagnosisUpdPair,diagnosisOutTypes= resetIntegerOutput(updateOutput(newPairs.copy(),codeType,diagnosis=0,procedure=1,drugs =1,all =0))\n",
    "\n",
    "print(f\"\\n total # records: {len(diagnosisUpdPair)} \\n total # of codes: {len(diagnosisOutTypes)}\")\n",
    "\n",
    "print(\"\\n Storing all the information related to TSequential disease prediction...\")\n",
    "storeFiles(diagnosisUpdPair,diagnosisOutTypes,codeType,types,reverseTypes,diagnosisOutputFile)\n",
    "print(\"\\n Completed...\")\n",
    "print(\"\\n All the preprocessing step has been completed, Now use the data in the outputData folder to build the model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c47e5-9afc-47e1-bd4d-7e9e8c122754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
